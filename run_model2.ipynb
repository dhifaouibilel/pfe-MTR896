{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 82,
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from alibi.explainers import ALE, plot_ale\n",
    "import joblib\n",
    "\n",
    "from utils import helpers as hpr\n",
    "from utils import constants\n",
    "import utils.classifier_util as clas_util\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "from db.db_manager import MongoManager\n",
    "mongo_manager = MongoManager()"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_man_ana = pd.read_csv(\"./Files/manual_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_man_ana[:len(df_man_ana)//2].to_csv(\"./Files/mohammed.csv\", index=None)\n",
    "df_man_ana[len(df_man_ana)//2:].to_csv(\"./Files/jamel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = constants.get_metrics()\n",
    "# metric_imp = pd.read_csv(osp.join('.', 'Files', 'third_metric_importances.csv'))\n",
    "# metric_imp = metric_imp.set_index('m')['imp'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dependent_changes = pd.read_csv(osp.join('.', 'Files', 'all_dependencies.csv'))\n",
    "df_dependent_changes = mongo_manager.read_all('dependencies2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_changes = set(hpr.flatten_list(df_dependent_changes[['Source', 'Target']].values))\n",
    "# cross_pro_changes = set(hpr.flatten_list(df_dependent_changes.loc[df_dependent_changes['is_cross']==True, ['Source', 'Target']].values))\n",
    "# within_pro_changes = dependent_changes.difference(cross_pro_changes)"
   ]
  },
  {
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "df_changes = hpr.combine_openstack_data(changes_path=\"/Changes3/\")\n",
    "df_changes = df_changes[df_changes['status']!=\"NEW\"]\n",
    "# df_changes['changed_files'] = df_changes['changed_files'].map(hpr.combine_changed_file_names)\n",
    "# df_changes['commit_message'] = df_changes['commit_message'].map(hpr.preprocess_change_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "code = [\"def purge_data(args):\",\n",
    "    \"    \\\"\\\"\\\"Run data purge process\",\n",
    "    \"    @raises Exception should the purge fail\\\"\\\"\\\"\",\n",
    "    \"    hookenv.action_set({\",\n",
    "    \"        'output': utils.purge_stale_soft_deleted_rows(\",\n",
    "    \"            before=hookenv.action_get('before'),\",\n",
    "    \"        )\",\n",
    "    \"    })\",\n",
    "    \"\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "tree = ast.parse(\"\\n\".join(code))  # Generates the AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method calls: 3\n",
      "Variables used: {'utils', 'hookenv'}\n",
      "Functions defined: ['purge_data']\n",
      "Imports: []\n"
     ]
    }
   ],
   "source": [
    "class CodeAnalyzer(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.method_calls = 0\n",
    "        self.variables = set()  # Stores unique variable names\n",
    "        self.functions = []\n",
    "        self.imports = []\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        # Count method/function calls (e.g., print(), foo())\n",
    "        self.method_calls += 1\n",
    "        self.generic_visit(node)  # Continue traversing child nodes\n",
    "\n",
    "    def visit_Name(self, node):\n",
    "        # Track variable names (e.g., x, y)\n",
    "        if isinstance(node.ctx, ast.Load):  # Only count reads, not writes\n",
    "            self.variables.add(node.id)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        # Track function definitions (e.g., foo)\n",
    "        self.functions.append(node.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        # Track imports (e.g., import os)\n",
    "        for alias in node.names:\n",
    "            self.imports.append(alias.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        # Track from-imports (e.g., from sys import path)\n",
    "        self.imports.append(f\"{node.module}.{[alias.name for alias in node.names][0]}\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "# Analyze the code\n",
    "analyzer = CodeAnalyzer()\n",
    "analyzer.visit(tree)\n",
    "\n",
    "print(\"Method calls:\", analyzer.method_calls)\n",
    "print(\"Variables used:\", analyzer.variables)\n",
    "print(\"Functions defined:\", analyzer.functions)\n",
    "print(\"Imports:\", analyzer.imports)"
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_changes = hpr.combine_openstack_data()\n",
    "\n",
    "df_changes = mongo_manager.read_filtered_changes()\n",
    "df_changes['changed_files'] = df_changes['changed_files'].map(hpr.combine_changed_file_names)\n",
    "df_changes['commit_message'] = df_changes['commit_message'].map(hpr.preprocess_change_description)\n",
    "# df_changes = df_changes[df_changes['number'].isin(dependent_changes)]\n",
    "# all_change_ids = df_changes['number'].unique()\n",
    "# df_changes['reviewers'] = df_changes['reviewers'].map(ast.literal_eval)\n",
    "# df_changes['reviewers'] = df_changes['reviewers'].map(lambda x: [rev['_account_id'] for rev in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = datetime(2014, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['project', 'branch', 'subject', 'status', 'created', 'insertions',\n",
      "       'deletions', 'reviewers', 'number', 'owner_account_id',\n",
      "       'commit_message', 'changed_files'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# df_changes = df_changes[(df_changes['status']!='NEW')&(df_changes['created']>=min_date)]\n",
    "print(df_changes.columns)\n",
    "# df_changes = df_changes.drop_duplicates(subset=['change_id'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_files = dict(zip(df_changes['number'], df_changes['changed_files']))\n",
    "changes_description = dict(zip(df_changes['number'], df_changes['commit_message']))\n",
    "# added_lines = dict(zip(df_changes['number'], df_changes['added_lines']))\n",
    "# deleted_lines = dict(zip(df_changes['number'], df_changes['deleted_lines']))\n",
    "added_lines = dict(zip(df_changes['number'], df_changes['insertions']))\n",
    "deleted_lines = dict(zip(df_changes['number'], df_changes['deletions']))"
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps = pd.read_csv(\"./Files/source_target_evolution_clean.csv\")"
=======
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dependencies = pd.read_csv(osp.join(\".\", \"Files\", \"Preliminary\", \"deps_ident.csv\"))\n",
    "# df_dependencies = df_dependencies.loc[(df_dependencies['Source_status']!='NEW')&(df_dependencies['Target_status']!='NEW')]\n",
    "# df_dependencies['related'] = 1"
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_changes = set(hpr.flatten_list(df_deps[['Source', 'Target']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_changes['is_dependent'] = df_changes['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_dependent\n",
       "0    675706\n",
       "1     49357\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_changes['is_dependent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "MERGED       578933\n",
       "ABANDONED    133290\n",
       "NEW           12840\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_changes.loc[df_changes['is_dependent']!=2, \"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clas_util.combine_features()\n",
    "df = df.drop(columns=['num_build_failures'])\n",
    "# df = pd.merge(\n",
    "#     left=df, \n",
    "#     right=df_changes[['number', 'created', 'project', 'owner_account_id']], \n",
    "#     left_on='number', \n",
    "#     right_on='number', \n",
    "#     how='inner',\n",
    "#     suffixes=('_source', '_target')\n",
    "# )\n",
    "# df['is_dependent'] = df['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)\n",
    "# df['is_cross'] = df['number'].map(is_cross_project)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_past_changes(row, sampling=True):\n",
    "    days_offset = row['created'] - timedelta(days=38.06)\n",
    "    source_changes = df_changes.loc[\n",
    "        (df_changes['status'] == 'MERGED') &\n",
    "        (df_changes['created'] < row['created']) &\n",
    "        (df_changes['created'] >= days_offset),\n",
    "        ['number']\n",
    "    ]\n",
    "    if (len(source_changes) > 0) and (sampling == True):\n",
    "        source_changes = source_changes.sample(n=30, replace=True, random_state=42)\n",
    "\n",
    "    source_changes = source_changes['number'].tolist()\n",
    "\n",
    "    # if len(source_changes) >= 60:\n",
    "    #     source_changes = random.sample(source_changes, 60)\n",
    "    \n",
    "    source_changes += df_dependencies.loc[\n",
    "        (df_dependencies['Target']==row['Target']), \n",
    "        'Source'].tolist()\n",
    "    return set(source_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_common_dev_pctg(row):\n",
    "    dev_source = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']),\n",
    "        'owner_account_id'\n",
    "    ].unique()\n",
    "    dev_target = df.loc[\n",
    "        (df['project'] == row['project_target']) &\n",
    "        (df['created'] < row['created_target']),\n",
    "        'owner_account_id'\n",
    "    ].unique()\n",
    "\n",
    "    union = len(set(dev_source).union(dev_target))\n",
    "    intersect = len(set(dev_source).intersection(dev_target))\n",
    "    return intersect/union if union != 0 else 0\n",
    "\n",
    "def count_dev_in_src_change(row):\n",
    "    changes_nbr = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']) &\n",
    "        (df['owner_account_id'] == row['owner_account_id_target']),\n",
    "        'number'\n",
    "    ].nunique()\n",
    "\n",
    "    return changes_nbr\n",
    "\n",
    "def count_rev_in_src_change(row):\n",
    "    account_id = row['owner_account_id_target']\n",
    "    reviewers = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']) & \n",
    "        (df['owner_account_id'] != account_id), 'reviewers'].values\n",
    "    rev_exists = [account_id in reviewers_list for reviewers_list in reviewers]\n",
    "    return sum(rev_exists)\n",
    "\n",
    "def count_src_trgt_co_changed(row):\n",
    "    return len(df_dependent_changes[\n",
    "        (df_dependent_changes['project_source'] == row['project_source']) &\n",
    "        (df_dependent_changes['project_target'] == row['project_target']) &\n",
    "        (df_dependent_changes['created_target'] < row['created_target'])\n",
    "    ])\n",
    "\n",
    "def get_features_labels():\n",
    "    X = pd.DataFrame({})\n",
    "    X_path = osp.join('.', 'Files', 'Data', 'Model3')\n",
    "    for f in hpr.list_file(X_path):\n",
    "        X_item = pd.read_csv(f'{X_path}/{f}')\n",
    "        X = pd.concat((X, X_item))\n",
    "    X.sort_values(by=['Target', 'Source'], inplace=True)\n",
    "    \n",
    "    y = X['related']\n",
    "\n",
    "    # X.drop(columns=['Source', 'Target', 'project', 'owner_account_id', 'number_target', 'number_source', 'number', 'created_target', 'created_source', 'related'], inplace=True)\n",
    "    X.drop(columns=['Source', 'Target', 'related'], inplace=True)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_features(X, fold):\n",
    "    print(f'******** Started assigning pairs of changes for Fold {fold}')\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df, \n",
    "        left_on='Source', \n",
    "        right_on='number', \n",
    "        how='inner',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df, \n",
    "        left_on='Target', \n",
    "        right_on='number', \n",
    "        how='inner',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "    # y = X['related'].values\n",
    "    # X.drop(columns=['related', 'number_source', 'number_target'], axis=1, inplace=True)\n",
    "    X.drop(columns=['number_source', 'number_target'], inplace=True)\n",
    "\n",
    "    # if X.empty == False:\n",
    "    #     X.to_csv(osp.join('.', 'Files', 'Data', 'Pairs', f'{target}.csv'), index=None)\n",
    "\n",
    "    return X\n",
    "\n",
    "    \n",
    "def assign_pair_features(X):\n",
    "    # print(f'******** Assigning pairs\\'s features')\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df[['number', 'owner_account_id', 'project']], \n",
    "        left_on='Source', \n",
    "        right_on='number', \n",
    "        how='left',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "\n",
    "    X.drop(columns=['owner_account_id_source', 'project_source', 'owner_account_id_target', 'project_target'], axis=1, inplace=True)\n",
    "\n",
    "    # print(f'******** Pairs\\'s features were assigned successfully...')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric1 = mongo_manager.read_all('metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metric1.drop(columns=['is_dependent'], inplace=True)\n",
    "# df_metric1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Files/Data/Test/6.csv processed successfully...\n",
      "./Files/Data/Test/7.csv processed successfully...\n",
      "./Files/Data/Test/5.csv processed successfully...\n",
      "./Files/Data/Test/4.csv processed successfully...\n",
      "./Files/Data/Test/0.csv processed successfully...\n",
      "./Files/Data/Test/1.csv processed successfully...\n",
      "./Files/Data/Test/3.csv processed successfully...\n",
      "./Files/Data/Test/2.csv processed successfully...\n",
      "./Files/Data/Test/9.csv processed successfully...\n",
      "./Files/Data/Test/8.csv processed successfully...\n"
     ]
    }
   ],
   "source": [
    "test_path = osp.join('.', 'Files', 'Data', 'Test')\n",
    "test_files = hpr.list_file(test_path)\n",
    "\n",
    "for fn in test_files[:]:\n",
    "    file_path = f'{test_path}/{fn}'\n",
    "    # print(f'Processing {file_path}')\n",
    "    df_test = pd.read_csv(file_path)\n",
    "    df_test.drop(columns = ['number_source', 'number_target'], inplace=True)\n",
    "\n",
    "    # columns_to_delete = [col for col in df_test.columns if col.endswith('source') or col.endswith('target')]\n",
    "    # df_test.drop(columns = columns_to_delete, inplace=True)\n",
    "    # df_test = pd.merge(\n",
    "    #         left=df_test, \n",
    "    #         right=df_metric1, \n",
    "    #         left_on='Source', \n",
    "    #         right_on='number', \n",
    "    #         how='inner',\n",
    "    #         suffixes=('_target', '_source')\n",
    "    #     )\n",
    "    # df_test = pd.merge(\n",
    "    #         left=df_test, \n",
    "    #         right=df_metric1, \n",
    "    #         left_on='Target', \n",
    "    #         right_on='number', \n",
    "    #         how='inner',\n",
    "    #         suffixes=('_source', '_target')\n",
    "    #     )\n",
    "    # df_test = df_test[['Source', 'Target', 'related']+constants.PAIR_METRICS]\n",
    "    # df_test = assign_features(df_test, fn)\n",
    "    df_test.to_csv(file_path, index=None)\n",
    "    print(f'{file_path} processed successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176238, '6.csv')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test),fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = osp.join('.', 'Files', 'Data', 'Pipeline')\n",
    "test_files = hpr.list_file(test_path)\n",
    "\n",
    "for fn in test_files:\n",
    "    file_path = f'{test_path}/{fn}'\n",
    "    print(f'Processing {file_path}')\n",
    "    df_test = pd.read_csv(file_path)\n",
    "    df_test['num_shrd_file_tkns'] = df_test[['Source', 'Target']].apply(clas_util.compute_filenames_shared_tokens, args=(changed_files,), axis=1)\n",
    "    df_test['num_shrd_desc_tkns'] = df_test[['Source', 'Target']].apply(clas_util.compute_shared_desc_tokens, args=(changes_description,), axis=1)\n",
    "    df_test['related'] = df_test['related'].fillna(False)\n",
    "    df_test.to_csv(file_path, index=None)\n",
    "    print(f'{file_path} processed successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classifiers = clas_util.load_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(osp.join(\".\", \"Results\", \"Correlation\", \"second_model.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_changed_lines = pd.read_csv(osp.join(\".\", \"Files\", \"changed_lines.csv\"))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join(\".\", \"Files\", \"file-metrics\")\n",
    "combined_output = hpr.combine_file_metrics(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_empty_values(row, c):\n",
    "    # print(f\"{row[c]=}\")\n",
    "    if not row[c]:\n",
    "        splits = c.split(\"_\")\n",
    "        src_or_trgt = splits[-1].capitalize()\n",
    "        metric = \"_\".join(splits[:-1])\n",
    "        # print(row[src_or_trgt], metric)\n",
    "        new_value = combined_output.loc[combined_output[\"number\"]==row[src_or_trgt], metric].values[0]\n",
    "        print(new_value)\n",
    "        row[c] = new_value\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Start training with classifier: ET and Developer type: All...\n",
      "Start training with classifier: RF and Developer type: All...\n",
      "Start training with classifier: XGBoost and Developer type: All...\n",
      "XGBoost, Fold: 1, Precision: 0.0048226254700016345, Recall: 0.9076923076923077, F1-Score: 0.009594275957394911, F2-Score: 0.023611333440051223, AUC: 0.9300305754259042, Brier: 0.047642514911508754\n",
      "XGBoost, Fold: 2, Precision: 0.0034291949185566205, Recall: 0.8, F1-Score: 0.006829116871022815, F2-Score: 0.01685694582790591, AUC: 0.8740813861097148, Brier: 0.051870255460400194\n",
      "XGBoost, Fold: 3, Precision: 0.006536918734214827, Recall: 0.88, F1-Score: 0.01297743695620115, F2-Score: 0.031741451450007216, AUC: 0.9262800937229427, Brier: 0.027458799492916835\n",
      "XGBoost, Fold: 4, Precision: 0.007109617373319545, Recall: 0.9016393442622951, F1-Score: 0.01410799025266128, F2-Score: 0.03446115288220551, AUC: 0.9358870739251589, Brier: 0.029881438289601554\n",
      "XGBoost, Fold: 5, Precision: 0.007837226827430294, Recall: 0.896551724137931, F1-Score: 0.01553862244135664, F2-Score: 0.03786223969710208, AUC: 0.9353353377644474, Brier: 0.02589873198801953\n",
      "XGBoost, Fold: 6, Precision: 0.008631713554987212, Recall: 0.8571428571428571, F1-Score: 0.017091311916442475, F2-Score: 0.04148740012292563, AUC: 0.9168279299101345, Brier: 0.023515470006512093\n",
      "XGBoost, Fold: 7, Precision: 0.008244545915778792, Recall: 0.9027777777777778, F1-Score: 0.016339869281045753, F2-Score: 0.039769946157611355, AUC: 0.9350727918979453, Brier: 0.03265159669895946\n",
      "XGBoost, Fold: 8, Precision: 0.004458161865569273, Recall: 0.896551724137931, F1-Score: 0.008872206108172668, F2-Score: 0.021856086079354405, AUC: 0.9352865246907266, Brier: 0.025988725841088047\n",
      "XGBoost, Fold: 9, Precision: 0.003186235462800701, Recall: 0.9090909090909091, F1-Score: 0.006350214319733291, F2-Score: 0.015710919088766692, AUC: 0.9414004965622613, Brier: 0.02629588861533808\n",
      "XGBoost, Fold: 10, Precision: 0.0035246017200056393, Recall: 0.8928571428571429, F1-Score: 0.007021485746383935, F2-Score: 0.01734906315058987, AUC: 0.9326266874362573, Brier: 0.027612464854732895\n",
      "XGBoost, Precision: 0.005778084184266454, Recall: 0.8844303787099153, AUC: 0.9262828897445494, Brier: 0.031881588615907744\n",
      "Start training with classifier: AdaBoost and Developer type: All...\n",
      "Start training with classifier: MLP and Developer type: All...\n",
      "Start training with classifier: ET and Developer type: Different...\n",
      "Start training with classifier: RF and Developer type: Different...\n",
      "Start training with classifier: XGBoost and Developer type: Different...\n",
      "XGBoost, Fold: 1, Precision: 0.0, Recall: 0.0, F1-Score: 0.0, F2-Score: 0.0, AUC: 0.4791791000533565, Brier: 0.04164558763082177\n",
      "XGBoost, Fold: 2, Precision: 0.00017861927301955882, Recall: 0.6666666666666666, F1-Score: 0.00035714285714285714, F2-Score: 0.000892140244446427, AUC: 0.8104195236438313, Brier: 0.04583115011789363\n",
      "XGBoost, Fold: 3, Precision: 0.0026789131266743206, Recall: 0.7777777777777778, F1-Score: 0.005339435545385202, F2-Score: 0.01321253303133258, AUC: 0.8780551121162401, Brier: 0.021682560005320872\n",
      "XGBoost, Fold: 4, Precision: 0.0009489166534872687, Recall: 0.5, F1-Score: 0.0018942383583267562, F2-Score: 0.0047088369172814315, AUC: 0.7376210557669773, Brier: 0.024780238514204647\n",
      "XGBoost, Fold: 5, Precision: 0.0005516734093416697, Recall: 0.6, F1-Score: 0.001102333272092596, F2-Score: 0.002748259435690729, AUC: 0.7892287081187993, Brier: 0.021550084028284237\n",
      "XGBoost, Fold: 6, Precision: 0.0018857250612860645, Recall: 0.5882352941176471, F1-Score: 0.0037593984962406013, F2-Score: 0.00930925339787749, AUC: 0.7840414233677999, Brier: 0.020177793006300803\n",
      "XGBoost, Fold: 7, Precision: 0.001525320317266626, Recall: 0.625, F1-Score: 0.0030432136335970784, F2-Score: 0.0075528700906344415, AUC: 0.7987366803192518, Brier: 0.027550016398819287\n",
      "XGBoost, Fold: 8, Precision: 0.0006446067898581865, Recall: 0.6, F1-Score: 0.00128783000643915, F2-Score: 0.003209242618741977, AUC: 0.7894417354508886, Brier: 0.02112512996063725\n",
      "XGBoost, Fold: 9, Precision: 0.0, Recall: 0.0, F1-Score: 0.0, F2-Score: 0.0, AUC: 0.4897613169423753, Brier: 0.020485690611256293\n",
      "XGBoost, Fold: 10, Precision: 0.00016191709844559586, Recall: 0.25, F1-Score: 0.00032362459546925567, F2-Score: 0.0008074935400516795, AUC: 0.6128499891781279, Brier: 0.02431144463814197\n",
      "XGBoost, Precision: 0.0008575691729379291, Recall: 0.46076797385620905, AUC: 0.7169334644957648, Brier: 0.026913969491168078\n",
      "Start training with classifier: AdaBoost and Developer type: Different...\n",
      "Start training with classifier: MLP and Developer type: Different...\n",
      "Start training with classifier: ET and Developer type: Same...\n",
      "Start training with classifier: RF and Developer type: Same...\n",
      "Start training with classifier: XGBoost and Developer type: Same...\n",
      "XGBoost, Fold: 1, Precision: 0.034746760895170786, Recall: 0.921875, F1-Score: 0.06696935300794551, F2-Score: 0.15097236438075742, AUC: 0.6451378853564547, Brier: 0.6182775479503573\n",
      "XGBoost, Fold: 2, Precision: 0.025703794369645042, Recall: 0.8076923076923077, F1-Score: 0.0498220640569395, F2-Score: 0.11400651465798045, AUC: 0.5709310555609175, Brier: 0.6557511256651658\n",
      "XGBoost, Fold: 3, Precision: 0.019933554817275746, Recall: 0.9375, F1-Score: 0.03903708523096942, F2-Score: 0.09185548071034905, AUC: 0.7348457817951157, Brier: 0.46373626373626375\n",
      "XGBoost, Fold: 4, Precision: 0.03467799009200283, Recall: 1.0, F1-Score: 0.06703146374829001, F2-Score: 0.15226848974518334, AUC: 0.6653581943081452, Brier: 0.6535697172975563\n",
      "XGBoost, Fold: 5, Precision: 0.04093567251461988, Recall: 0.9245283018867925, F1-Score: 0.0784, F2-Score: 0.17388218594748048, AUC: 0.6842980492484809, Brier: 0.5439093484419264\n",
      "XGBoost, Fold: 6, Precision: 0.046169989506820566, Recall: 0.9565217391304348, F1-Score: 0.08808808808808809, F2-Score: 0.19349164467897978, AUC: 0.6566048186098035, Brier: 0.6244002741603838\n",
      "XGBoost, Fold: 7, Precision: 0.04141566265060241, Recall: 0.9821428571428571, F1-Score: 0.07947976878612717, F2-Score: 0.17719072164948454, AUC: 0.6382443775736458, Brier: 0.6849462365591398\n",
      "XGBoost, Fold: 8, Precision: 0.019524617996604415, Recall: 0.9583333333333334, F1-Score: 0.03826955074875208, F2-Score: 0.09026687598116169, AUC: 0.8007607352486872, Brier: 0.354492486967188\n",
      "XGBoost, Fold: 9, Precision: 0.013717421124828532, Recall: 1.0, F1-Score: 0.02706359945872801, F2-Score: 0.06501950585175553, AUC: 0.7304086989126359, Brier: 0.5351693338295497\n",
      "XGBoost, Fold: 10, Precision: 0.026172300981461286, Recall: 1.0, F1-Score: 0.05100956429330499, F2-Score: 0.11846001974333663, AUC: 0.7694889003613836, Brier: 0.4553799082100969\n",
      "XGBoost, Precision: 0.030299776494903154, Recall: 0.9488593539185726, AUC: 0.689607849697527, Brier: 0.5589632242817628\n",
      "Start training with classifier: AdaBoost and Developer type: Same...\n",
      "Start training with classifier: MLP and Developer type: Same...\n"
=======
      "Start training with ET classifier...\n",
      "Start training with RF classifier...\n",
      "Start training with XGBoost classifier...\n",
      "XGBoost, Fold: 1, Precision: 0.02152179950013885, Recall: 0.8908045977011494, AUC: 0.9059855790465675, Brier: 0.07889242449617596\n",
      "XGBoost, Fold: 2, Precision: 0.02529167645446715, Recall: 0.8972222222222223, AUC: 0.9140923986857056, Brier: 0.06910465605419887\n",
      "XGBoost, Fold: 3, Precision: 0.01998434960573045, Recall: 0.9352112676056338, AUC: 0.9240586444588704, Brier: 0.08705170029526245\n",
      "XGBoost, Fold: 4, Precision: 0.020395115401828527, Recall: 0.9410029498525073, AUC: 0.9282637173150771, Brier: 0.08442798417319237\n",
      "XGBoost, Fold: 5, Precision: 0.021378736478269218, Recall: 0.9382022471910112, AUC: 0.9248943530693846, Brier: 0.08835886012395978\n",
      "XGBoost, Fold: 6, Precision: 0.020756784632243924, Recall: 0.9333333333333333, AUC: 0.9242035783302494, Brier: 0.08489102657099175\n",
      "XGBoost, Fold: 7, Precision: 0.021607605877268798, Recall: 0.9420289855072463, AUC: 0.9291822424650955, Brier: 0.08361420352023968\n",
      "XGBoost, Fold: 8, Precision: 0.021184897414107076, Recall: 0.9614325068870524, AUC: 0.9366200814014565, Brier: 0.08809401644086855\n",
      "XGBoost, Fold: 9, Precision: 0.02140041299042613, Recall: 0.9447513812154696, AUC: 0.9272279406337167, Brier: 0.09022240147499423\n",
      "XGBoost, Fold: 10, Precision: 0.022086264912817375, Recall: 0.9352331606217616, AUC: 0.922627726198161, Brier: 0.08992304667752626\n",
      "XGBoost, Precision: 0.02156076432672975, Recall: 0.9319222652137388, AUC: 0.9237156261604286, Brier: 0.08445803198274099\n",
      "Start training with AdaBoost classifier...\n",
      "Start training with MLP classifier...\n"
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
     ]
    }
   ],
   "source": [
    "# training_results = {key: None for key in ensemble_classifiers.keys()}\n",
    "training_results = []\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "clf_path = osp.join('.', 'Results')\n",
    "\n",
    "df_feat_impo = pd.DataFrame()\n",
<<<<<<< HEAD
    "df_feat_impact = pd.DataFrame()\n",
    "\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "\n",
    "for dev_type in ['All', 'Different', 'Same']:\n",
    "    # if dev_type != 'All':\n",
    "    #     continue\n",
=======
    "# df_feat_impact = pd.DataFrame()\n",
    "\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "    \n",
    "df_feat_impo = pd.DataFrame()\n",
    "df_feat_impact = pd.DataFrame()\n",
    "    \n",
    "for label, ens_clf in ensemble_classifiers.items():\n",
    "    print(f'Start training with {label} classifier...')\n",
    "\n",
    "    if label != 'XGBoost':\n",
    "        continue\n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "    for label, ens_clf in ensemble_classifiers.items():\n",
    "        print(f'Start training with classifier: {label} and Developer type: {dev_type}...')\n",
    "\n",
<<<<<<< HEAD
    "        if label != 'XGBoost':\n",
    "            continue\n",
    "        top3_results = {i: None for i in range(10)}\n",
    "        top5_results = {i: None for i in range(10)}\n",
    "        top7_results = {i: None for i in range(10)}\n",
    "        top10_results = {i: None for i in range(10)}\n",
    "        top20_results = {i: None for i in range(20)}\n",
    "        top30_results = {i: None for i in range(20)}\n",
    "        top40_results = {i: None for i in range(20)}\n",
    "        top50_results = {i: None for i in range(20)}\n",
    "        top60_results = {i: None for i in range(20)}\n",
    "        top70_results = {i: None for i in range(20)}\n",
    "        top80_results = {i: None for i in range(20)}\n",
    "        top90_results = {i: None for i in range(20)}\n",
    "        top100_results = {i: None for i in range(20)}\n",
=======
    "\n",
    "    for fold in range(0, 10):\n",
    "\n",
    "        # if fold not in [9]:\n",
    "        #     continue\n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "        auc_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        f1_scores = []\n",
    "        f2_scores = []\n",
    "        brier_scores = []\n",
    "        feature_importances = []\n",
    "        features = []\n",
    "        corr_features = []\n",
    "        redundant_features = []\n",
    "\n",
    "        # for config in [\n",
    "        #     'Source_train_dependent',\n",
    "        #     # 'Source_train_independent',\n",
    "        #     # 'Source_test_dependent',\n",
    "        #     # 'Source_test_independent',\n",
    "        #     # 'Source_train_test_dependent',\n",
    "        #     # 'Source_train_test_independent',\n",
    "        # ]:\n",
    "        for fold in range(0, 10):\n",
    "\n",
<<<<<<< HEAD
    "            # if fold not in [9]:\n",
    "            #     continue\n",
    "\n",
    "            clone_clf = clone(ens_clf)\n",
=======
    "        # X_train = X_train.drop(columns=['Source', 'Target', 'related'])\n",
    "        # X_train.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"), index=None)\n",
    "\n",
    "        # X_train.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"), index=None)\n",
    "        X_train = X_train.drop(columns=['Source', 'Target', 'related', 'Source_date', 'Source_author', 'Target_date', 'Target_author', 'is_cross', 'Source_repo', 'Target_repo', 'last_mth_dep_proj_nbr_source', 'last_mth_dep_proj_nbr_target'])\n",
    "        corr_path = osp.join('.', 'Results', 'Correlation')\n",
    "        # if fold == 0:\n",
    "        #     df_features = pd.DataFrame({'Feat': X_train.columns.tolist()})\n",
    "        #     for f in range(0, 10):\n",
    "        #         df_features[f\"Fold{f}\"] = [1]*len(df_features)\n",
    "        #     df_features.to_csv(f\"{corr_path}/second_model.csv\", index=None)\n",
    "        \n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "            # Split training data into features and labels\n",
    "            X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"))\n",
    "            X_train.fillna(0, inplace=True)\n",
    "\n",
<<<<<<< HEAD
    "            # if config in ['Source_train_dependent', 'Source_train_test_dependent']:\n",
    "            #     X_train = X_train[X_train['Source'].isin(dependent_changes)]\n",
    "            # elif config in ['Source_train_independent', 'Source_train_test_independent']:\n",
    "            #     X_train = X_train[~X_train['Source'].isin(dependent_changes)]\n",
    "            # if dev_type == \"Different\":\n",
    "            #     X_train = X_train[X_train['Source_author']!=X_train['Target_author']]\n",
    "            # elif dev_type == \"Same\":\n",
    "            #     X_train = X_train[X_train['Source_author']==X_train['Target_author']]\n",
    "\n",
    "            y_train = X_train['related']\n",
    "\n",
    "            # X_train = X_train.drop(columns=[\"related\"])\n",
    "            # pd.DataFrame({'col': X_train.columns.tolist()}).to_csv(\"test.csv\", index=None)\n",
    "            # df_test = pd.concat((df_test, X_train.iloc[:1]))\n",
    "            # desc_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold)\n",
    "            # subject_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, \"subject\")\n",
    "            # add_lines_model = clas_util.doc2vec_model(df_changed_lines, X_train[['Source', 'Target']].values, fold, 'added_lines')\n",
    "            # del_lines_model = clas_util.doc2vec_model(df_changed_lines, X_train[['Source', 'Target']].values, fold, 'deleted_lines')\n",
    "\n",
    "            # X_train = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_train, 'commit_message', 'desc')\n",
    "            # X_train = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_train, 'subject', 'subject')\n",
    "            # X_train = clas_util.compute_embdedding_similarity(df_changed_lines, add_lines_model, X_train, 'added_lines', 'add_lines')\n",
    "            # X_train = clas_util.compute_embdedding_similarity(df_changed_lines, del_lines_model, X_train, 'deleted_lines', 'del_lines')\n",
    "\n",
    "            # X_train.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"), index=None)\n",
    "            X_train = X_train.drop(columns=['Source', 'Target', 'related', 'Source_date', 'Source_author', 'Target_date', 'Target_author', 'add_lines_sim', 'del_lines_sim', 'is_cross'])\n",
    "            ################# TO REMOVE\n",
    "            # if dev_type != 'All':\n",
    "            #     ros = RandomUnderSampler(random_state=0)\n",
    "            \n",
    "            #     # Perform under-sampling of the majority class(es)\n",
    "            #     X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "            #################\n",
    "            # corr_path = osp.join('.', 'Results', 'Correlation')\n",
    "            # if fold == 0:\n",
    "            #     df_features = pd.DataFrame({'Feat': X_train.columns.tolist()})\n",
    "            #     for f in range(0, 10):\n",
    "            #         df_features[f\"Fold{f}\"] = [1]*len(df_features)\n",
    "            #     df_features.to_csv(f\"{corr_path}/second_model.csv\", index=None)\n",
    "            \n",
=======
    "       \n",
    "        if not os.path.exists(corr_path):\n",
    "            os.makedirs(corr_path)\n",
    "            \n",
    "        # pd.DataFrame({'Features': corr_features}).to_csv(f'{corr_path}/{fold+1}.csv', index=None)\n",
    "        # plt.figure(figsize=(6,12))\n",
    "        # dissimilarity = 1 - abs(X_train.corr())\n",
    "        \n",
    "        # Z = linkage(squareform(dissimilarity), 'complete')\n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "            # conduct the correlation analysis\n",
    "            # if fold == 0:\n",
    "            \n",
    "\n",
<<<<<<< HEAD
=======
    "        # threshold = 0.3 * max(Z[:, 2])  # Scale threshold based on the maximum distance in the dendrogram\n",
    "        # plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "        # # # # Adjust the layout to make sure labels fit\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'{corr_path}/second_model/{fold}.pdf')\n",
    "        # continue\n",
    "\n",
    "        # corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        # Remove highly correlated features from the training set\n",
    "        # X_train = X_train.drop(columns=corr_features)\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        # redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "\n",
    "        # Remove indepandent variables explained by others\n",
    "        # X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # if fold == 0:\n",
    "        #     break\n",
    "\n",
    "        # Instantiate the OverSampler class then fit it on the each fold training dataset\n",
    "        # features = X_train.columns.tolist()\n",
    "        # print(f'len(X_train) {len(X_train)}')\n",
    "\n",
    "        # Columns to exclude in the test set\n",
    "        # cols_exluded = corr_features + redundant_features \n",
    "\n",
    "        #Train the Random Forest Classifier on the training fold set \n",
    "        clone_clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Save model\n",
    "        model_filename = osp.join('Models/Model_2', f\"{label}_fold{fold+1}.pkl\")\n",
    "        joblib.dump(clone_clf, model_filename)\n",
    "\n",
    "        # rf_ale = ALE(clone_clf.predict, feature_names=X_train.columns.tolist())\n",
    "        # rf_exp = rf_ale.explain(X_train.to_numpy())\n",
    "        # plot_ale(rf_exp, features=ale_features, n_cols=4, fig_kw={'figwidth':14, 'figheight': 7})\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'./Results/ALE/third_model/ale_{fold+1}_model.pdf', format='pdf')\n",
    "        # continue\n",
    "\n",
    "        X_test = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"))\n",
    "        y_test = X_test['related']\n",
    "        X_test = X_test.drop(columns=[\"related\"])\n",
    "        # X_test_pairs = X_test[['Source', 'Target', 'related']]\n",
    "\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'commit_message', 'desc')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'subject', 'subject')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_test, 'added_lines', 'add_lines')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_test, 'deleted_lines', 'del_lines')\n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "        \n",
    "            # if not os.path.exists(corr_path):\n",
    "            #     os.makedirs(corr_path)\n",
    "                \n",
    "            # pd.DataFrame({'Features': corr_features}).to_csv(f'{corr_path}/{fold+1}.csv', index=None)\n",
    "            # plt.figure(figsize=(6,12))\n",
    "            # dissimilarity = 1 - abs(X_train.corr())\n",
    "            # Z = linkage(squareform(dissimilarity), 'complete')\n",
    "\n",
<<<<<<< HEAD
    "            # dendrogram(Z, labels=X_train.columns, orientation='left')\n",
=======
    "        # print(X_train.columns, )\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_pred = clone_clf.predict(X_test)\n",
    "        \n",
    "       \n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "            # threshold = 0.3 * max(Z[:, 2])  # Scale threshold based on the maximum distance in the dendrogram\n",
    "            # plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "            # # # Adjust the layout to make sure labels fit\n",
    "            # plt.tight_layout()\n",
    "            # plt.savefig(f'{corr_path}/second_model/{fold}.pdf')\n",
    "\n",
    "            corr_features = df_features.loc[df_features[f'Fold{fold}']==fold, 'Feat'].tolist() + ['rev_in_src_change_nbr']\n",
    "            # Remove highly correlated features from the training set\n",
    "            X_train = X_train.drop(columns=corr_features, errors='ignore')\n",
    "\n",
    "            # Conduct redundancy analysis\n",
    "            redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "\n",
    "            # Remove indepandent variables explained by others\n",
    "            X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
<<<<<<< HEAD
    "            # if fold == 0:\n",
    "            #     break\n",
=======
    "            # binary_cols = list(constants.DESCRIPTION_METRICS.keys())\n",
    "            binary_cols = list(constants.DESCRIPTION.keys())\n",
    "            binary_cols = hpr.flatten_list([[f'{c}_source', f'{c}_target'] for c in binary_cols])\n",
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
    "\n",
    "            # Instantiate the OverSampler class then fit it on the each fold training dataset\n",
    "            # features = X_train.columns.tolist()\n",
    "            # print(f'len(X_train) {len(X_train)}')\n",
    "\n",
    "            # Columns to exclude in the test set\n",
    "            # cols_exluded = corr_features + redundant_features \n",
    "\n",
    "            # Train the Random Forest Classifier on the training fold set \n",
    "            clone_clf.fit(X_train, y_train)\n",
    "\n",
    "            X_test = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"temp100_15_{fold}.csv\"))\n",
    "            \n",
    "            # if config in ['Source_test_dependent', 'Source_train_test_dependent']:\n",
    "            #     X_test = X_test[X_test['Source'].isin(dependent_changes)]\n",
    "            # elif config in ['Source_test_independent', 'Source_train_test_independent']:\n",
    "            #     X_test = X_test[~X_test['Source'].isin(dependent_changes)]\n",
    "\n",
    "            # X_test = X_test[X_test['Source'].isin(dependent_changes)]\n",
    "            if dev_type == \"Different\":\n",
    "                X_test = X_test[X_test['Source_author']!=X_test['Target_author']]\n",
    "            elif dev_type == \"Same\":\n",
    "                X_test = X_test[X_test['Source_author']==X_test['Target_author']]\n",
    "\n",
    "            # X_test.fillna(0, inplace=True)\n",
    "            y_test = X_test['related']\n",
    "            # if len(y_test[y_test == 1]) == 0:\n",
    "            #     continue\n",
    "            # X_test = X_test.drop(columns=[\"related\"])\n",
    "            # X_test_pairs = X_test[['Source', 'Target', 'related']]\n",
    "\n",
    "            # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'commit_message', 'desc')\n",
    "            # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'subject', 'subject')\n",
    "            # X_test = clas_util.compute_embdedding_similarity(df_changed_lines, add_lines_model, X_test, 'added_lines', 'add_lines')\n",
    "            # X_test = clas_util.compute_embdedding_similarity(df_changed_lines, del_lines_model, X_test, 'deleted_lines', 'del_lines')\n",
    "            \n",
    "            # X_test = X_test.drop(columns=cols_dropped+corr_features+redundant_features)\n",
    "            # X_test = X_test.drop(columns=['Source', 'Target'])\n",
    "            # X_test.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"), index=None)\n",
    "            X_test_topk = X_test[['Source', 'Target', 'related']]\n",
    "            X_test_topk.reset_index(drop=True, inplace=True)\n",
    "            X_test = X_test[X_train.columns.tolist()]\n",
    "\n",
    "            # print(X_train.columns, )\n",
    "            # Test the Random Forest Classifier on the test fold set\n",
    "            if label != \"AdaBoost\":\n",
    "                y_probs = clone_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                # Set custom threshold\n",
    "                threshold = 0.75\n",
    "                y_pred = [1 if p >= threshold else 0 for p in y_probs]\n",
    "            else:\n",
    "                y_pred = clone_clf.predict(X_test)\n",
    "\n",
    "            # y_pred_prob = clone_clf.predict_proba(X_test)[:, 1]\n",
    "            # X_test_pairs['pred'] = y_pred_prob\n",
    "            # compute_top_k_prec_recal(X_test_pairs, label, fold+1)\n",
    "            # Compute topk precision and recall\n",
    "            df_topk = pd.merge(X_test_topk, pd.DataFrame({'pred': y_probs}), left_index=True, right_index=True)\n",
    "            top3_results[fold] = clas_util.compute_topk_precision_recall(df_topk)\n",
    "            top5_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=5)\n",
    "            top7_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=7)\n",
    "            top10_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=10)\n",
    "            top20_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=20)\n",
    "            top30_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=30)\n",
    "            top40_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=40)\n",
    "            top50_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=50)\n",
    "            top60_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=60)\n",
    "            top70_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=70)\n",
    "            top80_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=80)\n",
    "            top90_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=90)\n",
    "            top100_results[fold] = clas_util.compute_topk_precision_recall(df_topk, k=100)\n",
    "\n",
    "            precision_scores.append(precision_score(y_test, y_pred))\n",
    "            recall_scores.append(recall_score(y_test, y_pred))\n",
    "            f1_scores.append(f1_score(y_test, y_pred))\n",
    "            f2_scores.append(fbeta_score(y_test, y_pred, beta=2))\n",
    "            auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "            brier_scores.append(brier_score_loss(y_test, y_pred))\n",
    "\n",
    "            print(f\"{label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, F1-Score: {f1_scores[-1]}, F2-Score: {f2_scores[-1]}, AUC: {auc_scores[-1]}, Brier: {brier_scores[-1]}\")\n",
    "\n",
    "            # logging.debug(msg=f\"{label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}\")\n",
    "            if label == 'XGBoost': \n",
    "                df_feat_imp_item = pd.DataFrame({name: [val] for name, val in zip(X_train.columns.to_list(), clone_clf.feature_importances_)})\n",
    "                df_feat_impo = pd.concat((df_feat_impo, df_feat_imp_item))\n",
    "\n",
    "            if label not in ['MLP']:\n",
    "\n",
    "                binary_cols = list(constants.DESCRIPTION.keys())\n",
    "                binary_cols = hpr.flatten_list([[f'{c}_source', f'{c}_target'] for c in binary_cols])\n",
    "\n",
    "                # Step 1: Calculate the median of each column\n",
    "                medians = X_train.median()\n",
    "\n",
    "                # Step 2: Calculate the standard deviation of each column\n",
    "                std_devs = X_train.std()\n",
    "\n",
    "                # Step 3: Create a new dataframe starting with the median row\n",
    "                df_feat_impact_item = pd.DataFrame([medians])\n",
    "                for col in binary_cols:\n",
    "                    if col in X_train.columns.tolist():\n",
    "                        df_feat_impact_item[col] = 0\n",
    "                df_feat_impact_item = pd.concat([df_feat_impact_item] * (len(X_train.columns.to_list()) + 1), ignore_index=True)\n",
    "\n",
    "\n",
    "                # Step 4: Double the number of rows according to the number of features and add standard deviation to each column\n",
    "                for idx, col in zip(range(1, len(df_feat_impact_item.columns)+1), df_feat_impact_item.columns):\n",
    "                    # df_feat_impact_item.iloc[idx, idx-1] += std_devs[col]\n",
    "\n",
    "                    if col in binary_cols:\n",
    "                        df_feat_impact_item.iloc[idx, idx-1] = 1\n",
    "                    else:\n",
    "                        df_feat_impact_item.iloc[idx, idx-1] += std_devs[col]\n",
    "\n",
    "                df_feat_impact_item['pred'] = clone_clf.predict_proba(df_feat_impact_item)[:,1]\n",
    "                proba1 = df_feat_impact_item.iloc[0, -1]\n",
    "                df_feat_impact_item['impact'] = None\n",
    "\n",
    "                df_feat_impact_item.iloc[1:, -1] = 0 if proba1 == 0 else (df_feat_impact_item.iloc[1:, -2] - proba1) / proba1\n",
    "\n",
    "                df_feat_impact_item['fold'] = fold\n",
    "                df_feat_impact_item['Classifier'] = label\n",
    "                df_feat_impact_item['pair_type'] = dev_type\n",
    "\n",
    "                df_feat_impact = pd.concat((df_feat_impact, df_feat_impact_item))\n",
    "\n",
    "        # feature_importances /= (fold+1)\n",
    "        prec_avg = np.average(precision_scores)\n",
    "        recall_avg = np.average(recall_scores)\n",
    "        f1_avg = np.average(f1_scores)\n",
    "        f2_avg = np.average(f2_scores)\n",
    "        auc_avg = np.average(auc_scores)\n",
    "        brier_avg = np.average(brier_scores)\n",
    "\n",
    "        print(f\"{label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}, Brier: {brier_avg}\")\n",
    "\n",
    "        df_topk = pd.DataFrame({})\n",
    "        for df_topk_result in [top3_results, top5_results, top7_results, top10_results, top20_results, top30_results, top40_results, top50_results, top60_results, top70_results, top80_results, top90_results, top100_results]:\n",
    "            df_topk_item = pd.DataFrame({})\n",
    "            for df_fold_topk in df_topk_result.values():\n",
    "                df_topk_item = pd.concat((df_topk_item, df_fold_topk))\n",
    "    \n",
    "            if df_topk.empty:\n",
    "                df_topk = df_topk_item\n",
    "            else:\n",
    "                df_topk = pd.merge(\n",
    "                    df_topk, df_topk_item,\n",
    "                    on=\"Target\",\n",
    "                    how=\"left\"\n",
    "                )\n",
    "            \n",
    "\n",
    "        # training_results[label] = \n",
    "        training_results.append({\n",
    "            # 'Config': config,\n",
    "            'Developer': dev_type,\n",
    "            'Classifier': label,\n",
    "            'Precision': prec_avg,\n",
    "            'Recall': recall_avg,\n",
    "            'F1': f1_avg,\n",
    "            'F2': f2_avg,\n",
    "            'AUC': auc_avg,\n",
    "            'Brier': brier_avg,\n",
    "            'AUC Scores': auc_scores,\n",
    "            'Precision Scores': precision_scores,\n",
    "            'F1 Scores': f1_scores,\n",
    "            'F2 Scores': f2_scores,\n",
    "            'Recall Scores': recall_scores,\n",
    "            'Brier Scores': brier_scores\n",
    "        } | {col: df_topk[col].median() for col in df_topk.columns[1:]})\n",
    "        # training_results[label]['Precision Scores'] += precision_scores\n",
    "        # training_results[label]['AUC Scores'] += auc_scores\n",
    "        # training_results[label]['Recall Scores'] += recall_scores\n",
    "        # training_results[label]['Brier Scores'] += brier_scores"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns\n",
    "df_corr = pd.DataFrame({'Feat':X_train.columns})\n",
    "for i in range(10):\n",
    "    df_corr[f'Fold{i}']= None\n",
    "df_corr.to_csv('./Results/Correlation/first_model.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_cross\n",
      "last_mth_dep_proj_nbr_source\n",
      "last_mth_dep_proj_nbr_target\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"2.csv\"))\n",
    "for col in X_train.columns:\n",
    "    # print(col)\n",
    "    \n",
    "    if X_train[col].dtype in ['float64', 'int64'] and X_train[col].sum() == 0:\n",
    "        print(col)\n",
    "        \n",
    "# dissimilarity\n",
    "# X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"2.csv\"))\n",
    "# X_train['src_trgt_co_changed_nbr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
>>>>>>> 40415dd (Added backend API and incorporated local changes for MTR896 project)
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2_perf = pd.DataFrame(training_results)\n",
    "df_model2_perf.sort_values(\"AUC\", ascending=0, inplace=True)\n",
    "# df_model2_perf\n",
    "# df_model2_perf.to_csv(\"./Results/second_model_perf_new.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2_perf.iloc[:,[0, 1]+[n for n in range(-26, 0, 1)]].T # Target is dependent and Source is ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2_perf = pd.read_csv(\"./Results/second_model_perf_new.csv\")\n",
    "df_model2_perf.sort_values(\"AUC\", ascending=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Developer</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>AUC Difference (All - Different)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>10.304237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ET</td>\n",
       "      <td>8.932527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>15.978754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>15.848726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>15.516515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Developer Classifier  AUC Difference (All - Different)\n",
       "0           AdaBoost                         10.304237\n",
       "1                 ET                          8.932527\n",
       "2                MLP                         15.978754\n",
       "3                 RF                         15.848726\n",
       "4            XGBoost                         15.516515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the table to compute the difference\n",
    "pivot_df = df_model2_perf.pivot(index='Classifier', columns='Developer', values='AUC')\n",
    "\n",
    "# Calculate the AUC difference between All and Different\n",
    "pivot_df['AUC Difference (All - Different)'] = 100*(pivot_df['All'] - pivot_df['Different'])\n",
    "\n",
    "pivot_df.reset_index(inplace=True)\n",
    "pivot_df[['Classifier', 'AUC Difference (All - Different)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Performance of the \\nth{2} model when the pairs are made by (1) \\textbf{all}, (2) \\textbf{same}, and (3) \\textbf{different} developers.}\n",
      "\\label{tab:model2_perf_new}\n",
      "\\begin{adjustbox}{width=\\textwidth}\n",
      "\\begin{tabular}{llcccccccccc}\n",
      "\\toprule\n",
      "Classifier & Developer & top-3-prec (\\%) & top-3-recall (\\%) & top-5-prec (\\%) & top-5-recall (\\%) & top-7-prec (\\%) & top-7-recall (\\%) & top-10-prec (\\%) & top-10-recall (\\%) & AUC (\\%) & Brier Score \\\\\n",
      "\\midrule\n",
      "\\multirow{2}{*}{XGBoost} & All & \\textbf{33.33}\\ & \\textbf{100}\\ & 20\\ & \\textbf{100}\\ & 14.29\\ & \\textbf{100}\\ & 10\\ & \\textbf{100} & \\textbf{91.89}\\ & 0.039 \\\\\n",
      " & Different & 0\\ & 0\\ & 0\\ & 0\\ & 14.29\\ & \\textbf{100}\\ & 10\\ & \\textbf{100} & 76.38\\ & 0.029 \\\\\n",
      " & Same & \\textbf{33.33}\\ & \\textbf{100}\\ & \\textbf{25}\\ & \\textbf{100}\\ & \\textbf{25}\\ & \\textbf{100}\\ & \\textbf{20}\\ & \\textbf{100} & 73.07\\ & 0.454 \\\\\n",
      "\\hhline{~-----------}\n",
      "\\multirow{2}{*}{AdaBoost} & All & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 87.92\\ & 0.115 \\\\\n",
      " & Different & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 77.62\\ & 0.100 \\\\\n",
      " & Same & 0\\ & 0\\ & 20\\ & \\textbf{100}\\ & 14.29\\ & \\textbf{100}\\ & 11.11\\ & \\textbf{100} & 58.14\\ & 0.719 \\\\\n",
      "\\hhline{~-----------}\n",
      "\\multirow{2}{*}{RF} & All & \\textbf{33.33}\\ & \\textbf{100}\\ & 20\\ & \\textbf{100}\\ & 14.29\\ & \\textbf{100}\\ & 10\\ & \\textbf{100} & 86.31\\ & 0.021 \\\\\n",
      " & Same & \\textbf{33.33}\\ & \\textbf{100}\\ & 22.50\\ & \\textbf{100}\\ & \\textbf{25}\\ & \\textbf{100}\\ & \\textbf{20}\\ & \\textbf{100} & 76.37\\ & 0.288 \\\\\n",
      " & Different & 0\\ & 0\\ & 0\\ & 0\\ & 14.29\\ & \\textbf{100}\\ & 10\\ & \\textbf{100} & 70.47\\ & \\textbf{0.014} \\\\\n",
      "\\hhline{~-----------}\n",
      "\\multirow{2}{*}{MLP} & All & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 80.98\\ & 0.164 \\\\\n",
      " & Different & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 65\\ & 0.148 \\\\\n",
      " & Same & \\textbf{33.33}\\ & \\textbf{100}\\ & 20\\ & \\textbf{100}\\ & 16.67\\ & \\textbf{100}\\ & \\textbf{20}\\ & \\textbf{100} & 53.07\\ & 0.762 \\\\\n",
      "\\hhline{~-----------}\n",
      "\\multirow{2}{*}{ET} & All & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 76.57\\ & 0.214 \\\\\n",
      " & Different & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0\\ & 0 & 67.64\\ & 0.206 \\\\\n",
      " & Same & 0\\ & 0\\ & 20\\ & \\textbf{100}\\ & 16.67\\ & \\textbf{100}\\ & 16.67\\ & \\textbf{100} & 61.31\\ & 0.531 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "latex_code = \"\"\"\\\\begin{table}[h]\n",
    "\\\\centering\n",
    "\\\\caption{Performance of the \\\\nth{2} model when the pairs are made by (1) \\\\textbf{all}, (2) \\\\textbf{same}, and (3) \\\\textbf{different} developers.}\n",
    "\\\\label{tab:model2_perf_new}\n",
    "\\\\begin{adjustbox}{width=\\\\textwidth}\n",
    "\\\\begin{tabular}{llcccccccccc}\n",
    "\\\\toprule\n",
    "Classifier & Developer & top-3-prec (\\\\%) & top-3-recall (\\\\%) & top-5-prec (\\\\%) & top-5-recall (\\\\%) & top-7-prec (\\\\%) & top-7-recall (\\\\%) & top-10-prec (\\\\%) & top-10-recall (\\\\%) & AUC (\\\\%) & Brier Score \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "top3_precision_max = 100 * df_model2_perf['Top3_Precision'].max()\n",
    "top3_recall_max = 100 * df_model2_perf['Top3_Recall'].max()\n",
    "top5_precision_max = 100 * df_model2_perf['Top5_Precision'].max()\n",
    "top5_recall_max = 100 * df_model2_perf['Top5_Recall'].max()\n",
    "top7_precision_max = 100 * df_model2_perf['Top7_Precision'].max()\n",
    "top7_recall_max = 100 * df_model2_perf['Top7_Recall'].max()\n",
    "top10_precision_max = 100 * df_model2_perf['Top10_Precision'].max()\n",
    "top10_recall_max = 100 * df_model2_perf['Top10_Recall'].max()\n",
    "auc_max = 100 * df_model2_perf['AUC'].max()\n",
    "brier_min = df_model2_perf['Brier'].min()\n",
    "# Group by classifier and add rows\n",
    "classifiers = df_model2_perf['Classifier'].unique()\n",
    "for i, clf in enumerate(classifiers):\n",
    "    group = df_model2_perf[df_model2_perf['Classifier'] == clf]\n",
    "    for j, (_, row) in enumerate(group.iterrows()):\n",
    "        top3_precision_percent = 100 * row['Top3_Precision']  # Convert to percentage\n",
    "        if top3_precision_percent == top3_precision_max:\n",
    "            top3_precision_percent = \"\\\\textbf{\" + f\"{top3_precision_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top3_precision_percent = f\"{top3_precision_percent:.2f}\"\n",
    "        \n",
    "        top3_recall_percent = 100 * row['Top3_Recall']  # Convert to percentage\n",
    "        if top3_recall_percent == top3_recall_max:\n",
    "            top3_recall_percent = \"\\\\textbf{\" + f\"{top3_recall_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top3_recall_percent = f\"{top3_recall_percent:.2f}\"\n",
    "        \n",
    "        top5_precision_percent = 100 * row['Top5_Precision']  # Convert to percentage\n",
    "        if top5_precision_percent == top5_precision_max:\n",
    "            top5_precision_percent = \"\\\\textbf{\" + f\"{top5_precision_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top5_precision_percent = f\"{top5_precision_percent:.2f}\"\n",
    "        \n",
    "        top5_recall_percent = 100 * row['Top5_Recall']  # Convert to percentage\n",
    "        if top5_recall_percent == top5_recall_max:\n",
    "            top5_recall_percent = \"\\\\textbf{\" + f\"{top5_recall_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top5_recall_percent = f\"{top5_recall_percent:.2f}\"\n",
    "        \n",
    "        top7_precision_percent = 100 * row['Top7_Precision']  # Convert to percentage\n",
    "        if top7_precision_percent == top7_precision_max:\n",
    "            top7_precision_percent = \"\\\\textbf{\" + f\"{top7_precision_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top7_precision_percent = f\"{top7_precision_percent:.2f}\"\n",
    "        \n",
    "        top7_recall_percent = 100 * row['Top7_Recall']  # Convert to percentage\n",
    "        if top7_recall_percent == top7_recall_max:\n",
    "            top7_recall_percent = \"\\\\textbf{\" + f\"{top7_recall_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top7_recall_percent = f\"{top7_recall_percent:.2f}\"\n",
    "        \n",
    "        top10_precision_percent = 100 * row['Top10_Precision']  # Convert to percentage\n",
    "        if top10_precision_percent == top10_precision_max:\n",
    "            top10_precision_percent = \"\\\\textbf{\" + f\"{top10_precision_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top10_precision_percent = f\"{top10_precision_percent:.2f}\"\n",
    "        \n",
    "        top10_recall_percent = 100 * row['Top10_Recall']  # Convert to percentage\n",
    "        if top10_recall_percent == top10_recall_max:\n",
    "            top10_recall_percent = \"\\\\textbf{\" + f\"{top10_recall_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            top10_recall_percent = f\"{top10_recall_percent:.2f}\"\n",
    "        \n",
    "        # f2_percent = row['Top3_Recall'] * 100  # Convert to percentage\n",
    "        # if f2_percent == f2_max:\n",
    "        #     f2_percent = \"\\\\textbf{\" + f\"{f2_percent:.2f}\" + \"}\"\n",
    "        # else:\n",
    "        #     f2_percent = f\"{f2_percent:.2f}\"\n",
    "        \n",
    "        auc_percent = row['AUC'] * 100  # Convert to percentage\n",
    "        if auc_percent == auc_max:\n",
    "            auc_percent = \"\\\\textbf{\" +f\"{auc_percent:.2f}\" + \"}\"\n",
    "        else:\n",
    "            auc_percent = f\"{auc_percent:.2f}\"\n",
    "        \n",
    "        brier_score = row['Brier']\n",
    "        if brier_score == brier_min:\n",
    "            brier_score = \"\\\\textbf{\" +f\"{brier_score:.3f}\" + \"}\"\n",
    "        else:\n",
    "            brier_score = f\"{brier_score:.3f}\"\n",
    "\n",
    "        if j == 0:\n",
    "            latex_code += (\n",
    "                \"\\\\multirow{2}{*}{\" + clf + \"}\" +\n",
    "                f\" & {row['Developer']} & {top3_precision_percent}\\\\ & {top3_recall_percent}\\\\ & {top5_precision_percent}\\\\ & {top5_recall_percent}\\\\ & {top7_precision_percent}\\\\ & {top7_recall_percent}\\\\ & {top10_precision_percent}\\\\ & {top10_recall_percent} & \"\n",
    "                f\"{auc_percent}\\\\ & {brier_score} \\\\\\\\\\n\"\n",
    "            )\n",
    "        else:\n",
    "            latex_code += (\n",
    "                f\" & {row['Developer']} & {top3_precision_percent}\\\\ & {top3_recall_percent}\\\\ & {top5_precision_percent}\\\\ & {top5_recall_percent}\\\\ & {top7_precision_percent}\\\\ & {top7_recall_percent}\\\\ & {top10_precision_percent}\\\\ & {top10_recall_percent} & \"\n",
    "                f\"{auc_percent}\\\\ & {brier_score} \\\\\\\\\\n\"\n",
    "            )\n",
    "    \n",
    "    if i < len(classifiers) - 1:\n",
    "        latex_code += \"\\\\hhline{~-----------}\\n\"\n",
    "\n",
    "latex_code += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{adjustbox}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code.replace(\".00\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impo.fillna(0, inplace=True)\n",
    "# df_feat_impo[\"pair_type\"] = \"All\"\n",
    "# df_feat_impo.iloc[10:20, -1] = \"Different\"\n",
    "# df_feat_impo.iloc[20:, -1] = \"Same\"\n",
    "df_feat_impo.to_csv(osp.join('.', 'Results', 'Feature_importance', f'second_feat_impo_new.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deletions_source</th>\n",
       "      <th>is_corrective_source</th>\n",
       "      <th>is_refactoring_source</th>\n",
       "      <th>is_preventive_source</th>\n",
       "      <th>is_non_functional_source</th>\n",
       "      <th>has_feature_addition_source</th>\n",
       "      <th>is_merge_source</th>\n",
       "      <th>cross_project_changes_owner_source</th>\n",
       "      <th>pctg_cross_project_changes_owner_source</th>\n",
       "      <th>projects_contributed_owner_source</th>\n",
       "      <th>...</th>\n",
       "      <th>within_project_changes_owner_source</th>\n",
       "      <th>whole_changes_owner_source</th>\n",
       "      <th>description_word_count_source</th>\n",
       "      <th>code_churn_target</th>\n",
       "      <th>whole_changes_owner_target</th>\n",
       "      <th>within_project_changes_target</th>\n",
       "      <th>whole_within_project_changes_target</th>\n",
       "      <th>description_word_count_target</th>\n",
       "      <th>num_directory_files_source</th>\n",
       "      <th>pair_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.040331</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.047932</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.040331</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.047932</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.040331</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.047932</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   deletions_source  is_corrective_source  is_refactoring_source  \\\n",
       "0          0.010216              0.015564               0.007410   \n",
       "0          0.000000              0.000000               0.000000   \n",
       "0          0.000000              0.022261               0.009682   \n",
       "0          0.000000              0.019390               0.021497   \n",
       "0          0.000000              0.026158               0.017643   \n",
       "0          0.000000              0.021956               0.016794   \n",
       "0          0.000000              0.020439               0.013329   \n",
       "0          0.000000              0.018234               0.010318   \n",
       "0          0.000000              0.020512               0.011376   \n",
       "0          0.000000              0.014324               0.009389   \n",
       "0          0.010216              0.015564               0.007410   \n",
       "0          0.000000              0.000000               0.000000   \n",
       "0          0.000000              0.022261               0.009682   \n",
       "0          0.000000              0.019390               0.021497   \n",
       "0          0.000000              0.026158               0.017643   \n",
       "0          0.000000              0.021956               0.016794   \n",
       "0          0.000000              0.020439               0.013329   \n",
       "0          0.000000              0.018234               0.010318   \n",
       "0          0.000000              0.020512               0.011376   \n",
       "0          0.000000              0.014324               0.009389   \n",
       "0          0.010216              0.015564               0.007410   \n",
       "0          0.000000              0.000000               0.000000   \n",
       "0          0.000000              0.022261               0.009682   \n",
       "0          0.000000              0.019390               0.021497   \n",
       "0          0.000000              0.026158               0.017643   \n",
       "0          0.000000              0.021956               0.016794   \n",
       "0          0.000000              0.020439               0.013329   \n",
       "0          0.000000              0.018234               0.010318   \n",
       "0          0.000000              0.020512               0.011376   \n",
       "0          0.000000              0.014324               0.009389   \n",
       "\n",
       "   is_preventive_source  is_non_functional_source  \\\n",
       "0              0.002218                  0.001790   \n",
       "0              0.000000                  0.000000   \n",
       "0              0.011731                  0.008363   \n",
       "0              0.009994                  0.010119   \n",
       "0              0.012111                  0.007700   \n",
       "0              0.011071                  0.007995   \n",
       "0              0.010088                  0.007649   \n",
       "0              0.009930                  0.004246   \n",
       "0              0.011428                  0.008514   \n",
       "0              0.013720                  0.010010   \n",
       "0              0.002218                  0.001790   \n",
       "0              0.000000                  0.000000   \n",
       "0              0.011731                  0.008363   \n",
       "0              0.009994                  0.010119   \n",
       "0              0.012111                  0.007700   \n",
       "0              0.011071                  0.007995   \n",
       "0              0.010088                  0.007649   \n",
       "0              0.009930                  0.004246   \n",
       "0              0.011428                  0.008514   \n",
       "0              0.013720                  0.010010   \n",
       "0              0.002218                  0.001790   \n",
       "0              0.000000                  0.000000   \n",
       "0              0.011731                  0.008363   \n",
       "0              0.009994                  0.010119   \n",
       "0              0.012111                  0.007700   \n",
       "0              0.011071                  0.007995   \n",
       "0              0.010088                  0.007649   \n",
       "0              0.009930                  0.004246   \n",
       "0              0.011428                  0.008514   \n",
       "0              0.013720                  0.010010   \n",
       "\n",
       "   has_feature_addition_source  is_merge_source  \\\n",
       "0                     0.012592         0.000000   \n",
       "0                     0.000000         0.000000   \n",
       "0                     0.019637         0.005779   \n",
       "0                     0.008703         0.006483   \n",
       "0                     0.010958         0.006627   \n",
       "0                     0.009315         0.004770   \n",
       "0                     0.011596         0.005772   \n",
       "0                     0.010326         0.005609   \n",
       "0                     0.006473         0.004629   \n",
       "0                     0.006078         0.006949   \n",
       "0                     0.012592         0.000000   \n",
       "0                     0.000000         0.000000   \n",
       "0                     0.019637         0.005779   \n",
       "0                     0.008703         0.006483   \n",
       "0                     0.010958         0.006627   \n",
       "0                     0.009315         0.004770   \n",
       "0                     0.011596         0.005772   \n",
       "0                     0.010326         0.005609   \n",
       "0                     0.006473         0.004629   \n",
       "0                     0.006078         0.006949   \n",
       "0                     0.012592         0.000000   \n",
       "0                     0.000000         0.000000   \n",
       "0                     0.019637         0.005779   \n",
       "0                     0.008703         0.006483   \n",
       "0                     0.010958         0.006627   \n",
       "0                     0.009315         0.004770   \n",
       "0                     0.011596         0.005772   \n",
       "0                     0.010326         0.005609   \n",
       "0                     0.006473         0.004629   \n",
       "0                     0.006078         0.006949   \n",
       "\n",
       "   cross_project_changes_owner_source  \\\n",
       "0                            0.016976   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.016976   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.016976   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "0                            0.000000   \n",
       "\n",
       "   pctg_cross_project_changes_owner_source  projects_contributed_owner_source  \\\n",
       "0                                 0.006765                           0.023343   \n",
       "0                                 0.000000                           0.000000   \n",
       "0                                 0.008714                           0.014290   \n",
       "0                                 0.009070                           0.017468   \n",
       "0                                 0.007635                           0.015985   \n",
       "0                                 0.006846                           0.015956   \n",
       "0                                 0.009027                           0.015922   \n",
       "0                                 0.011110                           0.016064   \n",
       "0                                 0.011665                           0.018243   \n",
       "0                                 0.009931                           0.018220   \n",
       "0                                 0.006765                           0.023343   \n",
       "0                                 0.000000                           0.000000   \n",
       "0                                 0.008714                           0.014290   \n",
       "0                                 0.009070                           0.017468   \n",
       "0                                 0.007635                           0.015985   \n",
       "0                                 0.006846                           0.015956   \n",
       "0                                 0.009027                           0.015922   \n",
       "0                                 0.011110                           0.016064   \n",
       "0                                 0.011665                           0.018243   \n",
       "0                                 0.009931                           0.018220   \n",
       "0                                 0.006765                           0.023343   \n",
       "0                                 0.000000                           0.000000   \n",
       "0                                 0.008714                           0.014290   \n",
       "0                                 0.009070                           0.017468   \n",
       "0                                 0.007635                           0.015985   \n",
       "0                                 0.006846                           0.015956   \n",
       "0                                 0.009027                           0.015922   \n",
       "0                                 0.011110                           0.016064   \n",
       "0                                 0.011665                           0.018243   \n",
       "0                                 0.009931                           0.018220   \n",
       "\n",
       "   ...  within_project_changes_owner_source  whole_changes_owner_source  \\\n",
       "0  ...                             0.000000                    0.000000   \n",
       "0  ...                             0.036368                    0.084356   \n",
       "0  ...                             0.000000                    0.016476   \n",
       "0  ...                             0.000000                    0.017884   \n",
       "0  ...                             0.000000                    0.018466   \n",
       "0  ...                             0.000000                    0.018481   \n",
       "0  ...                             0.000000                    0.018891   \n",
       "0  ...                             0.000000                    0.019249   \n",
       "0  ...                             0.000000                    0.019059   \n",
       "0  ...                             0.000000                    0.019725   \n",
       "0  ...                             0.000000                    0.000000   \n",
       "0  ...                             0.036368                    0.084356   \n",
       "0  ...                             0.000000                    0.016476   \n",
       "0  ...                             0.000000                    0.017884   \n",
       "0  ...                             0.000000                    0.018466   \n",
       "0  ...                             0.000000                    0.018481   \n",
       "0  ...                             0.000000                    0.018891   \n",
       "0  ...                             0.000000                    0.019249   \n",
       "0  ...                             0.000000                    0.019059   \n",
       "0  ...                             0.000000                    0.019725   \n",
       "0  ...                             0.000000                    0.000000   \n",
       "0  ...                             0.036368                    0.084356   \n",
       "0  ...                             0.000000                    0.016476   \n",
       "0  ...                             0.000000                    0.017884   \n",
       "0  ...                             0.000000                    0.018466   \n",
       "0  ...                             0.000000                    0.018481   \n",
       "0  ...                             0.000000                    0.018891   \n",
       "0  ...                             0.000000                    0.019249   \n",
       "0  ...                             0.000000                    0.019059   \n",
       "0  ...                             0.000000                    0.019725   \n",
       "\n",
       "   description_word_count_source  code_churn_target  \\\n",
       "0                       0.000000           0.000000   \n",
       "0                       0.040331           0.035698   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.040331           0.035698   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.040331           0.035698   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "0                       0.000000           0.000000   \n",
       "\n",
       "   whole_changes_owner_target  within_project_changes_target  \\\n",
       "0                    0.000000                       0.000000   \n",
       "0                    0.116567                       0.047932   \n",
       "0                    0.020712                       0.000000   \n",
       "0                    0.018023                       0.000000   \n",
       "0                    0.016272                       0.000000   \n",
       "0                    0.014136                       0.000000   \n",
       "0                    0.016249                       0.000000   \n",
       "0                    0.014657                       0.000000   \n",
       "0                    0.016942                       0.000000   \n",
       "0                    0.018037                       0.000000   \n",
       "0                    0.000000                       0.000000   \n",
       "0                    0.116567                       0.047932   \n",
       "0                    0.020712                       0.000000   \n",
       "0                    0.018023                       0.000000   \n",
       "0                    0.016272                       0.000000   \n",
       "0                    0.014136                       0.000000   \n",
       "0                    0.016249                       0.000000   \n",
       "0                    0.014657                       0.000000   \n",
       "0                    0.016942                       0.000000   \n",
       "0                    0.018037                       0.000000   \n",
       "0                    0.000000                       0.000000   \n",
       "0                    0.116567                       0.047932   \n",
       "0                    0.020712                       0.000000   \n",
       "0                    0.018023                       0.000000   \n",
       "0                    0.016272                       0.000000   \n",
       "0                    0.014136                       0.000000   \n",
       "0                    0.016249                       0.000000   \n",
       "0                    0.014657                       0.000000   \n",
       "0                    0.016942                       0.000000   \n",
       "0                    0.018037                       0.000000   \n",
       "\n",
       "   whole_within_project_changes_target  description_word_count_target  \\\n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.052224                       0.032970   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.012844   \n",
       "0                             0.000000                       0.015365   \n",
       "0                             0.000000                       0.013794   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.052224                       0.032970   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.012844   \n",
       "0                             0.000000                       0.015365   \n",
       "0                             0.000000                       0.013794   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.052224                       0.032970   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.012844   \n",
       "0                             0.000000                       0.015365   \n",
       "0                             0.000000                       0.013794   \n",
       "0                             0.000000                       0.000000   \n",
       "0                             0.000000                       0.000000   \n",
       "\n",
       "   num_directory_files_source  pair_type  \n",
       "0                    0.000000        All  \n",
       "0                    0.000000        All  \n",
       "0                    0.010621        All  \n",
       "0                    0.000000        All  \n",
       "0                    0.000000        All  \n",
       "0                    0.000000        All  \n",
       "0                    0.008151        All  \n",
       "0                    0.009292        All  \n",
       "0                    0.008149        All  \n",
       "0                    0.007645        All  \n",
       "0                    0.000000  Different  \n",
       "0                    0.000000  Different  \n",
       "0                    0.010621  Different  \n",
       "0                    0.000000  Different  \n",
       "0                    0.000000  Different  \n",
       "0                    0.000000  Different  \n",
       "0                    0.008151  Different  \n",
       "0                    0.009292  Different  \n",
       "0                    0.008149  Different  \n",
       "0                    0.007645  Different  \n",
       "0                    0.000000       Same  \n",
       "0                    0.000000       Same  \n",
       "0                    0.010621       Same  \n",
       "0                    0.000000       Same  \n",
       "0                    0.000000       Same  \n",
       "0                    0.000000       Same  \n",
       "0                    0.008151       Same  \n",
       "0                    0.009292       Same  \n",
       "0                    0.008149       Same  \n",
       "0                    0.007645       Same  \n",
       "\n",
       "[30 rows x 64 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_impo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = df_feat_impact.reset_index(drop=True)\n",
    "df_feat_impact = df_feat_impact[df_feat_impact['impact'].notnull()]\n",
    "df_feat_impact.to_csv(osp.join('.', 'Results', 'Impact', 'second_model_feat_impact_new.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = pd.read_csv(osp.join('.', 'Results', 'Impact', 'second_model_feat_impact_new.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the additional data\n",
    "data = {\n",
    "    \"Feature\": [\n",
    "        \"dev_in_src_change_nbr\", \"src_trgt_co_changed_nbr\", \"num_shrd_desc_tkns\",\n",
    "        \"cmn_dev_pctg\", \"last_mth_cro_proj_nbr_source\", \"project_changes_owner_source\",\n",
    "        \"changed_files_overlap\", \"last_mth_cro_proj_nbr_target\", \"whole_changes_owner_target\",\n",
    "        \"whole_changes_owner_source\", \"last_mth_dep_proj_nbr_target\", \"is_corrective_source\",\n",
    "        \"projects_contributed_owner_target\", \"projects_contributed_owner_source\", \"num_shrd_file_tkns\",\n",
    "        \"is_preventive_target\", \"is_refactoring_source\", \"pctg_cross_project_changes_owner_target\",\n",
    "        \"subject_length_target\", \"num_file_types_source\", \"project_age_source\",\n",
    "        \"has_feature_addition_source\", \"subject_length_source\", \"desc_sim\",\n",
    "        \"is_preventive_source\", \"pctg_cross_project_changes_source\", \"last_mth_dep_proj_nbr_source\",\n",
    "        \"ratio_dep_chan_owner_source\", \"pctg_cross_project_changes_target\", \"pctg_cross_project_changes_owner_source\",\n",
    "        \"has_feature_addition_target\", \"ratio_dep_chan_owner_target\", \"is_corrective_target\",\n",
    "        \"description_word_count_target\", \"add_lines_sim\", \"is_non_functional_target\",\n",
    "        \"subject_sim\", \"project_age_target\", \"num_file_types_target\",\n",
    "        \"is_non_functional_source\", \"del_lines_sim\", \"project_changes_owner_target\",\n",
    "        \"is_merge_target\", \"is_refactoring_target\", \"whole_within_project_changes_target\",\n",
    "        \"within_project_changes_target\", \"is_merge_source\", \"num_directory_files_source\",\n",
    "        \"description_word_count_source\", \"code_churn_source\", \"within_project_changes_owner_source\",\n",
    "        \"code_churn_target\", \"description_length_target\", \"num_file_changes_source\",\n",
    "        \"num_directory_files_target\", \"cross_project_changes_target\", \"cross_project_changes_owner_source\",\n",
    "        \"deletions_source\", \"description_length_source\", \"insertions_target\",\n",
    "        \"num_file_changes_target\", \"whole_within_project_changes_source\", \"deletions_target\"\n",
    "    ],\n",
    "    \"Ranking\": [\n",
    "        1, 2, 3,\n",
    "        4, 4, 4,\n",
    "        5, 5, 5,\n",
    "        5, 6, 6,\n",
    "        7, 7, 7,\n",
    "        8, 8, 9,\n",
    "        9, 10, 10,\n",
    "        10, 10, 10,\n",
    "        10, 11, 11,\n",
    "        12, 12, 12,\n",
    "        12, 12, 12,\n",
    "        12, 13, 13,\n",
    "        14, 14, 14,\n",
    "        14, 14, 15,\n",
    "        16, 16, 17,\n",
    "        17, 17, 18,\n",
    "        18, 18, 18,\n",
    "        18, 19, 19,\n",
    "        20, 20, 20,\n",
    "        21, 21, 21,\n",
    "        21, 21, 21\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the dataframe\n",
    "df_most_impo_feat = pd.DataFrame(data)\n",
    "# df_most_impo_feat = df_most_impo_feat[df_most_impo_feat['Ranking']<=10]\n",
    "# df_most_impo_feat['Classifier'] = \"RF\"\n",
    "classifiers = df_feat_impact['Classifier'].unique().tolist()\n",
    "df_most_impo_feat['Classifier'] = [classifiers for _ in range(len(df_most_impo_feat))]\n",
    "df_most_impo_feat = df_most_impo_feat.explode(\"Classifier\")\n",
    "df_most_impo_feat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_in_src_change_nbr</td>\n",
       "      <td>1</td>\n",
       "      <td>ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_in_src_change_nbr</td>\n",
       "      <td>1</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_in_src_change_nbr</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_in_src_change_nbr</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>src_trgt_co_changed_nbr</td>\n",
       "      <td>2</td>\n",
       "      <td>ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>whole_within_project_changes_source</td>\n",
       "      <td>21</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>deletions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>deletions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>deletions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>deletions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Ranking Classifier\n",
       "0                  dev_in_src_change_nbr        1         ET\n",
       "1                  dev_in_src_change_nbr        1         RF\n",
       "2                  dev_in_src_change_nbr        1    XGBoost\n",
       "3                  dev_in_src_change_nbr        1   AdaBoost\n",
       "4                src_trgt_co_changed_nbr        2         ET\n",
       "..                                   ...      ...        ...\n",
       "247  whole_within_project_changes_source       21   AdaBoost\n",
       "248                     deletions_target       21         ET\n",
       "249                     deletions_target       21         RF\n",
       "250                     deletions_target       21    XGBoost\n",
       "251                     deletions_target       21   AdaBoost\n",
       "\n",
       "[252 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_impo_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_impact_to_fold(row):\n",
    "    # print(row)\n",
    "    for i in range(10):\n",
    "        row[f'fold{i}'] = df_feat_impact.loc[(df_feat_impact['Classifier']==row['Classifier'])&(df_feat_impact['fold']==i), [row['Feature'],  'fold', 'impact']].sort_values(by=row['Feature']).iloc[-1, -1]\n",
    "    return row\n",
    "\n",
    "def retrieve_impact(row, func):\n",
    "    df_sub = [row[f'fold{i}'] for i in range(10) if row[f'fold{i}'] != 0]\n",
    "    return func(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df_most_impo_feat = df_most_impo_feat.apply(map_impact_to_fold, axis=1)\n",
    "# df_most_impo_feat = df_most_impo_feat[df_most_impo_feat[\"Ranking\"]<=10]\n",
    "# df_most_impo_feat['mean'] = df_most_impo_feat.apply(retrieve_impact, args=(np.mean,), axis=1) \n",
    "df_most_impo_feat['median'] = df_most_impo_feat.apply(retrieve_impact, args=(np.median,), axis=1) \n",
    "# df_most_impo_feat['max'] = df_most_impo_feat.apply(retrieve_impact, args=(max,), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat = df_most_impo_feat[df_most_impo_feat[\"Classifier\"]==\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "      <th>fold3</th>\n",
       "      <th>fold4</th>\n",
       "      <th>fold5</th>\n",
       "      <th>fold6</th>\n",
       "      <th>fold7</th>\n",
       "      <th>fold8</th>\n",
       "      <th>fold9</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>description_word_count_target</td>\n",
       "      <td>12</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.175150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>-0.209010</td>\n",
       "      <td>-0.109815</td>\n",
       "      <td>-0.130275</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>-0.056762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>add_lines_sim</td>\n",
       "      <td>13</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>-0.196835</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>0.077061</td>\n",
       "      <td>-0.076688</td>\n",
       "      <td>-0.004029</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>is_non_functional_target</td>\n",
       "      <td>13</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.161575</td>\n",
       "      <td>-0.122923</td>\n",
       "      <td>-0.059584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050541</td>\n",
       "      <td>-0.143317</td>\n",
       "      <td>-0.091254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>subject_sim</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.554272</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.075565</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.056684</td>\n",
       "      <td>0.141730</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.043662</td>\n",
       "      <td>0.057894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>project_age_target</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.075919</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.044405</td>\n",
       "      <td>-0.141143</td>\n",
       "      <td>-0.298137</td>\n",
       "      <td>-0.097118</td>\n",
       "      <td>-0.297101</td>\n",
       "      <td>-0.070888</td>\n",
       "      <td>-0.166303</td>\n",
       "      <td>-0.208395</td>\n",
       "      <td>-0.119131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>num_file_types_target</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.045163</td>\n",
       "      <td>-0.004729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090301</td>\n",
       "      <td>-0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>is_non_functional_source</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>-0.044911</td>\n",
       "      <td>-0.075405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058707</td>\n",
       "      <td>-0.035292</td>\n",
       "      <td>-0.040102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>del_lines_sim</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.035568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>project_changes_owner_target</td>\n",
       "      <td>15</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.073777</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>-0.199812</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>-0.068741</td>\n",
       "      <td>-0.030921</td>\n",
       "      <td>-0.025926</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>-0.015827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>is_merge_target</td>\n",
       "      <td>16</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160743</td>\n",
       "      <td>0.114757</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.285350</td>\n",
       "      <td>0.052335</td>\n",
       "      <td>-0.046260</td>\n",
       "      <td>0.122760</td>\n",
       "      <td>0.118758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>is_refactoring_target</td>\n",
       "      <td>16</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>whole_within_project_changes_target</td>\n",
       "      <td>17</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.035568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>within_project_changes_target</td>\n",
       "      <td>17</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.035568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>is_merge_source</td>\n",
       "      <td>17</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100407</td>\n",
       "      <td>-0.042729</td>\n",
       "      <td>-0.057670</td>\n",
       "      <td>-0.051404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102843</td>\n",
       "      <td>-0.062773</td>\n",
       "      <td>-0.057670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>num_directory_files_source</td>\n",
       "      <td>18</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>-0.213789</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>-0.286975</td>\n",
       "      <td>-0.165122</td>\n",
       "      <td>-0.033112</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.009181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>description_word_count_source</td>\n",
       "      <td>18</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.027163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>code_churn_source</td>\n",
       "      <td>18</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.819995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.027163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>within_project_changes_owner_source</td>\n",
       "      <td>18</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.548789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.027163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>code_churn_target</td>\n",
       "      <td>18</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.035568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>description_length_target</td>\n",
       "      <td>19</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.155793</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.443740</td>\n",
       "      <td>0.381177</td>\n",
       "      <td>0.248434</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.059914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>num_file_changes_source</td>\n",
       "      <td>19</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.188428</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.094661</td>\n",
       "      <td>-0.481239</td>\n",
       "      <td>0.025486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>num_directory_files_target</td>\n",
       "      <td>20</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.132142</td>\n",
       "      <td>-0.091973</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.059914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>cross_project_changes_target</td>\n",
       "      <td>20</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.525059</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.028839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>cross_project_changes_owner_source</td>\n",
       "      <td>20</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.259086</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.028839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>deletions_source</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.925720</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.028839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>description_length_source</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.506383</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.028839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>insertions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.006548</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.042296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>num_file_changes_target</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.168768</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.028839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>whole_within_project_changes_source</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.065089</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.042296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>deletions_target</td>\n",
       "      <td>21</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.035568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Ranking Classifier     fold0  \\\n",
       "134        description_word_count_target       12    XGBoost  0.000000   \n",
       "138                        add_lines_sim       13    XGBoost  0.000000   \n",
       "142             is_non_functional_target       13    XGBoost  0.000000   \n",
       "146                          subject_sim       14    XGBoost  0.554272   \n",
       "150                   project_age_target       14    XGBoost -0.075919   \n",
       "154                num_file_types_target       14    XGBoost  0.000000   \n",
       "158             is_non_functional_source       14    XGBoost  0.000000   \n",
       "162                        del_lines_sim       14    XGBoost  0.000000   \n",
       "166         project_changes_owner_target       15    XGBoost -0.073777   \n",
       "170                      is_merge_target       16    XGBoost  0.000000   \n",
       "174                is_refactoring_target       16    XGBoost  0.122920   \n",
       "178  whole_within_project_changes_target       17    XGBoost  0.000000   \n",
       "182        within_project_changes_target       17    XGBoost  0.000000   \n",
       "186                      is_merge_source       17    XGBoost  0.000000   \n",
       "190           num_directory_files_source       18    XGBoost  0.000000   \n",
       "194        description_word_count_source       18    XGBoost  0.000000   \n",
       "198                    code_churn_source       18    XGBoost  0.000000   \n",
       "202  within_project_changes_owner_source       18    XGBoost  0.000000   \n",
       "206                    code_churn_target       18    XGBoost  0.000000   \n",
       "210            description_length_target       19    XGBoost -0.155793   \n",
       "214              num_file_changes_source       19    XGBoost -0.188428   \n",
       "218           num_directory_files_target       20    XGBoost  0.084189   \n",
       "222         cross_project_changes_target       20    XGBoost -0.525059   \n",
       "226   cross_project_changes_owner_source       20    XGBoost -0.259086   \n",
       "230                     deletions_source       21    XGBoost -0.925720   \n",
       "234            description_length_source       21    XGBoost -0.506383   \n",
       "238                    insertions_target       21    XGBoost  1.006548   \n",
       "242              num_file_changes_target       21    XGBoost -0.168768   \n",
       "246  whole_within_project_changes_source       21    XGBoost  0.065089   \n",
       "250                     deletions_target       21    XGBoost  0.000000   \n",
       "\n",
       "        fold1     fold2     fold3     fold4     fold5     fold6     fold7  \\\n",
       "134 -0.175150  0.000000  0.059914  0.009181 -0.209010 -0.109815 -0.130275   \n",
       "138  1.349130  0.003376 -0.196835  0.004759 -0.002686  0.077061 -0.076688   \n",
       "142  1.349130  0.000000 -0.161575 -0.122923 -0.059584  0.000000  0.000000   \n",
       "146  1.349130  0.075565  0.148000  0.056684  0.141730  0.149731  0.043662   \n",
       "150  1.349130  0.044405 -0.141143 -0.298137 -0.097118 -0.297101 -0.070888   \n",
       "154  1.349130  0.000000  0.000000 -0.001041 -0.045163 -0.004729  0.000000   \n",
       "158  1.349130  0.032676 -0.044911 -0.075405  0.000000  0.000000  0.000000   \n",
       "162  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "166  1.349130 -0.199812  0.031800 -0.068741 -0.030921 -0.025926 -0.005728   \n",
       "170  1.349130  0.000000  0.160743  0.114757  0.068376  0.285350  0.052335   \n",
       "174  1.349130  0.005933  0.000000 -0.078265  0.000000  0.080788  0.104304   \n",
       "178  0.252903  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "182  0.361048  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "186  1.349130  0.000000 -0.100407 -0.042729 -0.057670 -0.051404  0.000000   \n",
       "190  1.349130 -0.213789  0.059914  0.009181  0.062222 -0.286975 -0.165122   \n",
       "194 -0.084473  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "198 -0.819995  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "202 -0.548789  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "206  0.177404  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "210  1.349130  0.000000  0.059914  0.009181  0.443740  0.381177  0.248434   \n",
       "214  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "218  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.132142   \n",
       "222  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "226  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "230  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "234  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "238  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "242  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "246  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "250  1.349130  0.000000  0.059914  0.009181  0.062222  0.028839  0.025486   \n",
       "\n",
       "        fold8     fold9    median  \n",
       "134 -0.003708  0.042296 -0.056762  \n",
       "138 -0.004029  0.009180  0.003376  \n",
       "142 -0.050541 -0.143317 -0.091254  \n",
       "146  0.057894  0.000000  0.141730  \n",
       "150 -0.166303 -0.208395 -0.119131  \n",
       "154  0.000000 -0.090301 -0.004729  \n",
       "158 -0.058707 -0.035292 -0.040102  \n",
       "162 -0.003708  0.042296  0.035568  \n",
       "166 -0.003335  0.021813 -0.015827  \n",
       "170 -0.046260  0.122760  0.118758  \n",
       "174  0.011361  0.000000  0.080788  \n",
       "178 -0.003708  0.042296  0.035568  \n",
       "182 -0.003708  0.042296  0.035568  \n",
       "186 -0.102843 -0.062773 -0.057670  \n",
       "190 -0.033112  0.019045  0.009181  \n",
       "194 -0.003708  0.042296  0.027163  \n",
       "198 -0.003708  0.042296  0.027163  \n",
       "202 -0.003708  0.042296  0.027163  \n",
       "206 -0.003708  0.042296  0.035568  \n",
       "210 -0.003708  0.042296  0.059914  \n",
       "214 -0.094661 -0.481239  0.025486  \n",
       "218 -0.091973  0.042296  0.059914  \n",
       "222 -0.003708  0.042296  0.028839  \n",
       "226 -0.003708  0.042296  0.028839  \n",
       "230 -0.003708  0.042296  0.028839  \n",
       "234 -0.003708  0.042296  0.028839  \n",
       "238 -0.003708  0.042296  0.042296  \n",
       "242 -0.003708  0.042296  0.028839  \n",
       "246 -0.003708  0.042296  0.042296  \n",
       "250 -0.003708  0.042296  0.035568  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_impo_feat.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat.to_csv(osp.join('.', 'Results', 'second_feat_impact_import_new.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\caption{Ranking of 10 top important features of \\nth{2} model and their impacts.}\n",
      "\\label{tab:feat-imp-model2}\n",
      "\\begin{tabular}{lcc}\n",
      "\\toprule\n",
      "\\caption{Ranking of 10 top important features of \\nth{2} model and their impacts.} \\label{tab:feat-imp-model2}\n",
      "\n",
      "Feature & Ranking & Median impact \\\\\n",
      "\\midrule\n",
      "dev\\_in\\_src\\_change\\_nbr & 1 & 0.40 \\\\\n",
      "src\\_trgt\\_co\\_changed\\_nbr & 2 & 0.35 \\\\\n",
      "num\\_shrd\\_desc\\_tkns & 3 & 0.70 \\\\\n",
      "cmn\\_dev\\_pctg & 4 & 0.40 \\\\\n",
      "last\\_mth\\_cro\\_proj\\_nbr\\_source & 4 & -0.20 \\\\\n",
      "project\\_changes\\_owner\\_source & 4 & -0.08 \\\\\n",
      "changed\\_files\\_overlap & 5 & 0.18 \\\\\n",
      "last\\_mth\\_cro\\_proj\\_nbr\\_target & 5 & -0.13 \\\\\n",
      "whole\\_changes\\_owner\\_target & 5 & -0.18 \\\\\n",
      "whole\\_changes\\_owner\\_source & 5 & -0.08 \\\\\n",
      "last\\_mth\\_dep\\_proj\\_nbr\\_target & 6 & -0.10 \\\\\n",
      "is\\_corrective\\_source & 6 & 0.10 \\\\\n",
      "projects\\_contributed\\_owner\\_target & 7 & -0.17 \\\\\n",
      "projects\\_contributed\\_owner\\_source & 7 & -0.07 \\\\\n",
      "num\\_shrd\\_file\\_tkns & 7 & 0.16 \\\\\n",
      "is\\_preventive\\_target & 8 & 0.04 \\\\\n",
      "is\\_refactoring\\_source & 8 & -0.03 \\\\\n",
      "pctg\\_cross\\_project\\_changes\\_owner\\_target & 9 & 2.75 \\\\\n",
      "subject\\_length\\_target & 9 & -0.04 \\\\\n",
      "num\\_file\\_types\\_source & 10 & 0.02 \\\\\n",
      "project\\_age\\_source & 10 & -0.03 \\\\\n",
      "has\\_feature\\_addition\\_source & 10 & -0.02 \\\\\n",
      "subject\\_length\\_source & 10 & -0.02 \\\\\n",
      "desc\\_sim & 10 & 0.05 \\\\\n",
      "is\\_preventive\\_source & 10 & -0.02 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_81835/2509675578.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_most_impo_feat['Feature'] = df_most_impo_feat['Feature'].str.replace('_', r'\\_', regex=False)\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_81835/2509675578.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_most_impo_feat[\"median\"] = df_most_impo_feat[\"median\"].apply(lambda x: f\"{x:.2f}\")\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "df_most_impo_feat = df_most_impo_feat[df_most_impo_feat[\"Classifier\"]==\"RF\"]\n",
    "# Escape underscores in feature names\n",
    "df_most_impo_feat['Feature'] = df_most_impo_feat['Feature'].str.replace('_', r'\\_', regex=False)\n",
    "df_most_impo_feat[\"median\"] = df_most_impo_feat[\"median\"].apply(lambda x: f\"{x:.2f}\")\n",
    "latex_table = df_most_impo_feat[[\"Feature\", \"Ranking\", \"median\"]].to_latex(\n",
    "    index=False,\n",
    "    caption=\"Ranking of 10 top important features of \\\\nth{2} model and their impacts.\",\n",
    "    label=\"tab:feat-imp-model2\",\n",
    "    position='htbp',\n",
    "    column_format='lcc',\n",
    "    header=['Feature', 'Ranking', 'Median impact'],\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "# Add booktabs rules\n",
    "latex_table = latex_table.replace('\\\\toprule', '\\\\toprule\\n\\\\caption{Ranking of 10 top important features of \\\\nth{2} model and their impacts.} \\\\label{tab:feat-imp-model2}\\n')\n",
    "latex_table = latex_table.replace('\\\\midrule', '\\\\midrule')\n",
    "latex_table = latex_table.replace('\\\\bottomrule', '\\\\bottomrule')\n",
    "\n",
    "# Ensure we're using booktabs package\n",
    "# latex_table = \"latex_table\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h]\n",
      "\\caption{Ranking of 10 top important features of \\nth{2} model and their impacts.}\n",
      "\\label{tab:feat-imp-model2}\n",
      "\\centering\n",
      "\\begin{adjustbox}{width=\\textwidth}\n",
      "\\begin{tabular}{lrc*{10}{c}}\n",
      "\\toprule\n",
      "\\textbf{Feature} & \\textbf{Rank} & \\multicolumn{10}{c}{\\textbf{Impact on fold ...}} \\\\\n",
      "\\cmidrule(l){3-12} & & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\\\\n",
      "\\midrule\n",
      "src\\_trgt\\_co\\_changed\\_nbr & 1 & 0.43 & 2.75 & 0.18 & 0.54 & 0.37 & 0.31 & 0.38 & 0.31 & 0.21 & 0.48 \\\\\n",
      "\\hline\n",
      "dev\\_in\\_src\\_change\\_nbr & 1 & 0.40 & 2.75 & 0.26 & 0.50 & 0.65 & 0.20 & 0.42 & 0.47 & 0.21 & 0.42 \\\\\n",
      "\\hline\n",
      "cmn\\_dev\\_pctg & 2 & 0.38 & 2.75 & 0.16 & 0.24 & 0.31 & 0.24 & 0.28 & 0.27 & 0.11 & 0.44 \\\\\n",
      "\\hline\n",
      "num\\_shrd\\_desc\\_tkns & 2 & 1.07 & 2.75 & 0.47 & 0.89 & 0.78 & 0.58 & 0.86 & 0.90 & 0.50 & 0.81 \\\\\n",
      "\\hline\n",
      "whole\\_changes\\_owner\\_target & 3 & -0.02 & -0.46 & -0.16 & -0.11 & -0.18 & -0.08 & -0.20 & -0.27 & -0.23 & -0.25 \\\\\n",
      "\\hline\n",
      "whole\\_changes\\_owner\\_source & 3 & -0.02 & -0.33 & -0.05 & -0.02 & -0.08 & * & -0.08 & -0.10 & -0.19 & -0.15 \\\\\n",
      "\\hline\n",
      "project\\_changes\\_owner\\_source & 4 & -0.05 & -0.12 & -0.06 & -0.02 & -0.08 & -0.02 & -0.10 & -0.08 & -0.05 & -0.08 \\\\\n",
      "\\hline\n",
      "num\\_shrd\\_file\\_tkns & 4 & 0.12 & 2.75 & 0.10 & 0.13 & 0.22 & 0.02 & 0.20 & 0.37 & 0.03 & 0.27 \\\\\n",
      "\\hline\n",
      "changed\\_files\\_overlap & 4 & 0.14 & 1.63 & * & 0.13 & 0.04 & 0.03 & 0.14 & 0.18 & 0.08 & 0.13 \\\\\n",
      "\\hline\n",
      "desc\\_sim & 4 & 0.24 & 2.75 & 0.02 & -0.02 & 0.04 & * & -0.06 & 0.02 & -0.06 & -0.06 \\\\\n",
      "\\hline\n",
      "projects\\_contributed\\_owner\\_target & 5 & -0.05 & 2.75 & -0.13 & -0.15 & -0.24 & -0.15 & -0.32 & -0.29 & -0.34 & -0.23 \\\\\n",
      "\\hline\n",
      "subject\\_sim & 5 & -0.02 & 2.75 & -0.06 & 0.02 & 0.08 & -0.02 & 0.06 & 0.02 & 0.03 & 0.02 \\\\\n",
      "\\hline\n",
      "last\\_mth\\_cro\\_proj\\_nbr\\_source & 5 & -0.12 & 2.75 & -0.24 & -0.02 & -0.16 & -0.32 & -0.34 & -0.20 & -0.26 & -0.21 \\\\\n",
      "\\hline\n",
      "projects\\_contributed\\_owner\\_source & 6 & -0.02 & 2.75 & -0.03 & 0.02 & -0.12 & -0.12 & -0.12 & -0.04 & -0.08 & -0.02 \\\\\n",
      "\\hline\n",
      "project\\_age\\_source & 7 & 0.02 & 2.75 & * & -0.02 & -0.04 & -0.07 & -0.02 & -0.10 & 0.02 & 0.02 \\\\\n",
      "\\hline\n",
      "last\\_mth\\_cro\\_proj\\_nbr\\_target & 7 & -0.14 & 2.75 & -0.16 & -0.13 & -0.18 & -0.15 & -0.26 & -0.16 & -0.18 & -0.25 \\\\\n",
      "\\hline\n",
      "last\\_mth\\_dep\\_proj\\_nbr\\_target & 8 & -0.17 & 2.75 & -0.23 & -0.11 & -0.02 & -0.07 & -0.14 & -0.08 & -0.10 & -0.08 \\\\\n",
      "\\hline\n",
      "ratio\\_dep\\_chan\\_owner\\_source & 8 & -0.29 & 2.75 & -0.31 & -0.13 & -0.08 & -0.10 & -0.10 & -0.16 & -0.06 & -0.06 \\\\\n",
      "\\hline\n",
      "subject\\_length\\_source & 8 & * & -0.04 & 0.03 & 0.04 & * & -0.05 & -0.02 & -0.06 & -0.05 & * \\\\\n",
      "\\hline\n",
      "subject\\_length\\_target & 8 & -0.02 & -0.08 & -0.13 & -0.07 & * & 0.02 & -0.02 & -0.02 & -0.08 & 0.02 \\\\\n",
      "\\hline\n",
      "ratio\\_dep\\_chan\\_owner\\_target & 9 & -0.05 & 2.75 & 0.03 & 0.02 & 0.04 & -0.05 & 0.06 & * & -0.03 & 0.02 \\\\\n",
      "\\hline\n",
      "pctg\\_cross\\_project\\_changes\\_target & 9 & -0.10 & 2.75 & 0.08 & 0.04 & 0.06 & -0.02 & 0.02 & 0.12 & 0.06 & 0.17 \\\\\n",
      "\\hline\n",
      "pctg\\_cross\\_project\\_changes\\_source & 9 & 0.12 & 2.75 & 0.18 & 0.13 & 0.20 & 0.10 & 0.26 & 0.22 & 0.21 & 0.27 \\\\\n",
      "\\hline\n",
      "project\\_age\\_target & 9 & -0.05 & 2.75 & * & -0.02 & -0.06 & -0.02 & -0.02 & -0.02 & -0.03 & 0.02 \\\\\n",
      "\\hline\n",
      "last\\_mth\\_dep\\_proj\\_nbr\\_source & 9 & -0.07 & 2.75 & -0.10 & -0.07 & -0.18 & -0.17 & -0.16 & -0.06 & -0.21 & 0.02 \\\\\n",
      "\\hline\n",
      "project\\_changes\\_owner\\_target & 10 & * & 2.75 & -0.06 & 0.02 & 0.06 & -0.02 & -0.06 & -0.04 & -0.11 & -0.06 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for classifier == \"RF\"\n",
    "rf_df = df_most_impo_feat[df_most_impo_feat['Classifier'] == 'RF'].copy()\n",
    "\n",
    "# List of fold columns\n",
    "fold_cols = [f\"fold{i}\" for i in range(10)]\n",
    "\n",
    "# Group by Feature, keep the first Ranking per feature and average the folds\n",
    "rf_df = df_most_impo_feat.groupby('Feature').agg({\n",
    "    'Ranking': 'first',      # or 'min'/'max' if you prefer\n",
    "    **{col: 'max' for col in fold_cols}\n",
    "}).reset_index()\n",
    "\n",
    "# Define fold columns and select necessary ones\n",
    "fold_columns = [f'fold{i}' for i in range(10)]\n",
    "selected_columns = ['Feature', 'Ranking'] + fold_columns\n",
    "rf_df = rf_df[selected_columns]\n",
    "\n",
    "# Keep only top 10 ranked features\n",
    "rf_df = rf_df[rf_df['Ranking'] <= 10]\n",
    "rf_df.sort_values(\"Ranking\", inplace=True)\n",
    "\n",
    "# Escape underscores in feature names\n",
    "rf_df['Feature'] = rf_df['Feature'].str.replace('_', r'\\_', regex=False)\n",
    "\n",
    "# Format fold values: 2 decimal places, replace 0.00 with \"*\"\n",
    "for col in fold_columns:\n",
    "    rf_df[col] = rf_df[col].apply(lambda x: \"*\" if round(x, 3) == 0 else f\"{x:.2f}\")\n",
    "\n",
    "# Generate full LaTeX table (with tabular environment)\n",
    "latex_full = rf_df.to_latex(\n",
    "    index=False,\n",
    "    header=False,\n",
    "    column_format='lrc' + 'c' * 10,\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "# Split into lines\n",
    "lines = latex_full.splitlines()\n",
    "\n",
    "# Remove \\begin{tabular} and \\end{tabular} lines\n",
    "body_lines = []\n",
    "for line in lines:\n",
    "    if line.strip().startswith(r'\\begin{tabular}'):\n",
    "        continue\n",
    "    elif line.strip().startswith(r'\\end{tabular}'):\n",
    "        continue\n",
    "    elif line.strip().startswith(r'\\toprule'):\n",
    "        continue\n",
    "    elif line.strip().startswith(r'\\midrule'):\n",
    "        continue\n",
    "    elif line.strip().startswith(r'\\bottomrule'):\n",
    "        continue\n",
    "    else:\n",
    "        body_lines.append(line)\n",
    "\n",
    "# Insert \\midrule after each data row line\n",
    "new_body_lines = []\n",
    "for idx, line in enumerate(body_lines):\n",
    "    new_body_lines.append(line)\n",
    "    # Each row ends with \\\\ and contains & separating columns\n",
    "    if  '&' in line and line.strip().endswith(r'\\\\') and idx < len(body_lines) - 1 :\n",
    "        new_body_lines.append(r'\\hline')\n",
    "\n",
    "latex_body_with_lines = \"\\n\".join(new_body_lines)\n",
    "\n",
    "# Define your custom header (with the tabular environment)\n",
    "header = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\caption{Ranking of 10 top important features of \\nth{2} model and their impacts.}\n",
    "\\label{tab:feat-imp-model2}\n",
    "\\centering\n",
    "\\begin{adjustbox}{width=\\textwidth}\n",
    "\\begin{tabular}{lrc*{10}{c}}\n",
    "\\toprule\n",
    "\\textbf{Feature} & \\textbf{Rank} & \\multicolumn{10}{c}{\\textbf{Impact on fold ...}} \\\\\n",
    "\\cmidrule(l){3-12} & & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Footer closes the tabular environment\n",
    "footer = r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{adjustbox}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "# Combine all parts\n",
    "full_latex = header + latex_body_with_lines + footer\n",
    "\n",
    "print(full_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=[\"number\"], inplace=True)\n",
    "M1_METRICS = df.columns.tolist()\n",
    "CHANGE_METRICS = [col for col in constants.CHANGE_METRICS if col in M1_METRICS]\n",
    "TEXT_METRICS = [col for col in constants.TEXT_METRICS if col in M1_METRICS]\n",
    "DEVELOPER_METRICS = [col for col in constants.DEVELOPER_METRICS if col in M1_METRICS]\n",
    "PROJECT_METRICS = [col for col in constants.PROJECT_METRICS if col in M1_METRICS]\n",
    "FILE_METRICS = [col for col in constants.FILE_METRICS if col in M1_METRICS]\n",
    "CHANGE_METRICS = [f'{cm}_source' for cm in CHANGE_METRICS] + [f'{cm}_target' for cm in CHANGE_METRICS]\n",
    "TEXT_METRICS = [f'{cm}_source' for cm in TEXT_METRICS] + [f'{cm}_target' for cm in TEXT_METRICS]\n",
    "DEVELOPER_METRICS = [f'{cm}_source' for cm in DEVELOPER_METRICS] + [f'{cm}_target' for cm in DEVELOPER_METRICS]\n",
    "PROJECT_METRICS = [f'{cm}_source' for cm in PROJECT_METRICS] + [f'{cm}_target' for cm in PROJECT_METRICS]\n",
    "FILE_METRICS = [f'{cm}_source' for cm in FILE_METRICS] + [f'{cm}_target' for cm in FILE_METRICS]\n",
    "\n",
    "dimensions = {\n",
    "    'Change': CHANGE_METRICS,\n",
    "    'Text': TEXT_METRICS,\n",
    "    'Developer': DEVELOPER_METRICS,\n",
    "    'Project': PROJECT_METRICS,\n",
    "    'File': FILE_METRICS,\n",
    "    'Pairs': constants.PAIR_METRICS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with Change dimension...\n",
      "Change, Fold: 1, Precision: 0.03999379941094404, Recall: 0.8896551724137931, AUC: 0.922430242207128, Brier: 0.0449318983997748\n",
      "Change, Fold: 2, Precision: 0.04195345788266142, Recall: 0.8648648648648649, AUC: 0.9106976664734036, Brier: 0.043670843813297125\n",
      "Change, Fold: 3, Precision: 0.040658775090066906, Recall: 0.8116438356164384, AUC: 0.8846991473710323, Brier: 0.042567144827794154\n",
      "Change, Fold: 4, Precision: 0.035505759823260215, Recall: 0.8302583025830258, AUC: 0.8911343648184168, Brier: 0.04824808825372947\n",
      "Change, Fold: 5, Precision: 0.03969291081345965, Recall: 0.8496503496503497, AUC: 0.9034831580245533, Brier: 0.04290713597403256\n",
      "Change, Fold: 6, Precision: 0.04164422904325974, Recall: 0.8315412186379928, AUC: 0.8943445030994459, Brier: 0.0431328581724994\n",
      "Change, Fold: 7, Precision: 0.043258832011535686, Recall: 0.8275862068965517, AUC: 0.893187033431117, Brier: 0.041506890701619836\n",
      "Change, Fold: 8, Precision: 0.04114420062695925, Recall: 0.8045977011494253, AUC: 0.8817147223087594, Brier: 0.041506139887022724\n",
      "Change, Fold: 9, Precision: 0.04249341527655839, Recall: 0.9132075471698113, AUC: 0.9352818369759264, Brier: 0.04273517613822597\n",
      "Change, Fold: 10, Precision: 0.04116945107398568, Recall: 0.8380566801619433, AUC: 0.8998084576088985, Brier: 0.03868251846193023\n",
      "Change, Precision: 0.0407514831052691, Recall: 0.8461061879144196, AUC: 0.9016781132318681, Brier: 0.04298886946299262\n",
      "Start training with Text dimension...\n",
      "Text, Fold: 1, Precision: 0.03933715347684683, Recall: 0.8758620689655172, AUC: 0.9154975249024964, Brier: 0.0450329500588265\n",
      "Text, Fold: 2, Precision: 0.04278341934409855, Recall: 0.8682432432432432, AUC: 0.912743772790897, Brier: 0.042951157804141535\n",
      "Text, Fold: 3, Precision: 0.03966597077244259, Recall: 0.7808219178082192, AUC: 0.8695601554682598, Brier: 0.04209225017148974\n",
      "Text, Fold: 4, Precision: 0.03635783766544411, Recall: 0.8413284132841329, AUC: 0.89694030372045, Brier: 0.0476839664034098\n",
      "Text, Fold: 5, Precision: 0.03736571695469407, Recall: 0.8391608391608392, AUC: 0.8971348183083931, Brier: 0.0451314674066614\n",
      "Text, Fold: 6, Precision: 0.04074965612104539, Recall: 0.8494623655913979, AUC: 0.9023419251446648, Brier: 0.04501481540802434\n",
      "Text, Fold: 7, Precision: 0.04268077601410935, Recall: 0.8344827586206897, AUC: 0.8961694599333407, Brier: 0.04242100288952412\n",
      "Text, Fold: 8, Precision: 0.04053794428434198, Recall: 0.8084291187739464, AUC: 0.8832098318511802, Brier: 0.04233710204047373\n",
      "Text, Fold: 9, Precision: 0.0407953376756942, Recall: 0.8981132075471698, AUC: 0.9271755186344234, Brier: 0.04388237681249903\n",
      "Text, Fold: 10, Precision: 0.04114351941278733, Recall: 0.8623481781376519, AUC: 0.9113841084441897, Brier: 0.03977272727272727\n",
      "Text, Precision: 0.04014173317215044, Recall: 0.8458252111132808, AUC: 0.9012157419198296, Brier: 0.04363198162677774\n",
      "Start training with Developer dimension...\n",
      "Developer, Fold: 1, Precision: 0.03414221218961625, Recall: 0.8344827586206897, AUC: 0.8924824229043355, Brier: 0.04976072410731686\n",
      "Developer, Fold: 2, Precision: 0.034898750538560966, Recall: 0.8209459459459459, AUC: 0.8854887739916739, Brier: 0.05025189010320446\n",
      "Developer, Fold: 3, Precision: 0.031958762886597936, Recall: 0.7431506849315068, AUC: 0.8467470216353474, Brier: 0.05011269325574208\n",
      "Developer, Fold: 4, Precision: 0.0324636821820338, Recall: 0.8081180811808119, AUC: 0.8784350269598598, Brier: 0.05154663407295976\n",
      "Developer, Fold: 5, Precision: 0.0353309481216458, Recall: 0.8286713286713286, AUC: 0.890844561985465, Brier: 0.0472398727711402\n",
      "Developer, Fold: 6, Precision: 0.03804526074122663, Recall: 0.8315412186379928, AUC: 0.8922295830811461, Brier: 0.04735324737727236\n",
      "Developer, Fold: 7, Precision: 0.0376076872100729, Recall: 0.7827586206896552, AUC: 0.8688283192503145, Brier: 0.04548870141842323\n",
      "Developer, Fold: 8, Precision: 0.03419226957383548, Recall: 0.7931034482758621, AUC: 0.8719592848304056, Brier: 0.0495303804799436\n",
      "Developer, Fold: 9, Precision: 0.0363987759703656, Recall: 0.8528301886792453, AUC: 0.9030207890523455, Brier: 0.0469962072140973\n",
      "Developer, Fold: 10, Precision: 0.0362703791903279, Recall: 0.8016194331983806, AUC: 0.8798356859653846, Brier: 0.04225553857906799\n",
      "Developer, Precision: 0.03513087286042833, Recall: 0.8097221708831419, AUC: 0.880987146965628, Brier: 0.04805358893791679\n",
      "Start training with Project dimension...\n",
      "Project, Fold: 1, Precision: 0.03728461081402258, Recall: 0.8655172413793103, AUC: 0.9093197079716672, Brier: 0.0470612012155071\n",
      "Project, Fold: 2, Precision: 0.038449515473585494, Recall: 0.831081081081081, AUC: 0.8926681012350418, Brier: 0.04601538792559782\n",
      "Project, Fold: 3, Precision: 0.03558718861209965, Recall: 0.7534246575342466, AUC: 0.8541919501286203, Brier: 0.04548435485937841\n",
      "Project, Fold: 4, Precision: 0.033895657606997816, Recall: 0.8007380073800738, AUC: 0.8760876302711724, Brier: 0.0488827253353391\n",
      "Project, Fold: 5, Precision: 0.0355893536121673, Recall: 0.8181818181818182, AUC: 0.8860717343107185, Brier: 0.04631970960519929\n",
      "Project, Fold: 6, Precision: 0.03847435043304464, Recall: 0.8279569892473119, AUC: 0.8908106895655058, Brier: 0.046616481140386\n",
      "Project, Fold: 7, Precision: 0.04004071937563624, Recall: 0.8137931034482758, AUC: 0.8849317544074302, Brier: 0.04424922726533268\n",
      "Project, Fold: 8, Precision: 0.038059163059163056, Recall: 0.8084291187739464, AUC: 0.8817840003264238, Brier: 0.045182517899260526\n",
      "Project, Fold: 9, Precision: 0.03760989905568219, Recall: 0.8716981132075472, AUC: 0.9127362806463784, Brier: 0.04639529257519237\n",
      "Project, Fold: 10, Precision: 0.0412573673870334, Recall: 0.8502024291497976, AUC: 0.9056461167811388, Brier: 0.0391281512605042\n",
      "Project, Precision: 0.037624782542943234, Recall: 0.8241022559383409, AUC: 0.8894247965644096, Brier: 0.04553350490816975\n",
      "Start training with File dimension...\n",
      "File, Fold: 1, Precision: 0.04131168622407973, Recall: 0.8862068965517241, AUC: 0.9215342960694001, Brier: 0.04328619995236136\n",
      "File, Fold: 2, Precision: 0.04184584849487264, Recall: 0.8547297297297297, AUC: 0.905827146903754, Brier: 0.04329987164362929\n",
      "File, Fold: 3, Precision: 0.038396194359497114, Recall: 0.773972602739726, AUC: 0.8656066732091909, Brier: 0.043162647650779054\n",
      "File, Fold: 4, Precision: 0.03744821872410936, Recall: 0.8339483394833949, AUC: 0.8941689153859684, Brier: 0.04586624044126865\n",
      "File, Fold: 5, Precision: 0.043965824136703455, Recall: 0.8636363636363636, AUC: 0.912320312752671, Brier: 0.039197501793231365\n",
      "File, Fold: 6, Precision: 0.04244604316546763, Recall: 0.8458781362007168, AUC: 0.9015731588452758, Brier: 0.04298069992792504\n",
      "File, Fold: 7, Precision: 0.04502098435711561, Recall: 0.8137931034482758, AUC: 0.8874628692625899, Brier: 0.03919837009148869\n",
      "File, Fold: 8, Precision: 0.041012558869701725, Recall: 0.8007662835249042, AUC: 0.8798284554453877, Brier: 0.041455778544389324\n",
      "File, Fold: 9, Precision: 0.043548970003614025, Recall: 0.909433962264151, AUC: 0.9340206652561673, Brier: 0.04149432642931839\n",
      "File, Fold: 10, Precision: 0.04287775716347145, Recall: 0.8421052631578947, AUC: 0.9025423817723024, Brier: 0.0372580850522027\n",
      "File, Precision: 0.04178740854986327, Recall: 0.8424470680736882, AUC: 0.9004884874902708, Brier: 0.041719972152659386\n",
      "Start training with Pairs dimension...\n",
      "Pairs, Fold: 1, Precision: 0.01593061332861315, Recall: 0.6206896551724138, AUC: 0.7701323186352257, Brier: 0.08105064853511185\n",
      "Pairs, Fold: 2, Precision: 0.02236500679599654, Recall: 0.6114864864864865, AUC: 0.7763273232521661, Brier: 0.05955587211847367\n",
      "Pairs, Fold: 3, Precision: 0.022355118895059093, Recall: 0.5376712328767124, AUC: 0.7429005410052865, Brier: 0.05277361093313031\n",
      "Pairs, Fold: 4, Precision: 0.02201859956236324, Recall: 0.5940959409594095, AUC: 0.7689742273401252, Brier: 0.056890121599598845\n",
      "Pairs, Fold: 5, Precision: 0.02629416598192276, Recall: 0.6713286713286714, AUC: 0.8098535277969401, Brier: 0.0521957121845543\n",
      "Pairs, Fold: 6, Precision: 0.023822341857335127, Recall: 0.6344086021505376, AUC: 0.788097062189635, Brier: 0.0589012573075999\n",
      "Pairs, Fold: 7, Precision: 0.024252923343438718, Recall: 0.5793103448275863, AUC: 0.7634162072205044, Brier: 0.053305135296350524\n",
      "Pairs, Fold: 8, Precision: 0.024173027989821884, Recall: 0.5823754789272031, AUC: 0.7653797682662395, Brier: 0.05241776412425822\n",
      "Pairs, Fold: 9, Precision: 0.024067388688327317, Recall: 0.6037735849056604, AUC: 0.7765178717267972, Brier: 0.05145234044545724\n",
      "Pairs, Fold: 10, Precision: 0.020257537688442212, Recall: 0.5222672064777328, AUC: 0.7362605796455736, Brier: 0.05058728036669213\n",
      "Pairs, Precision: 0.022553672413132005, Recall: 0.5957407204112413, AUC: 0.7697859427078495, Brier: 0.0569129742911227\n"
     ]
    }
   ],
   "source": [
    "dimension_results = {key: [] for key in dimensions.keys()}\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "clf_path = osp.join('.', 'Results')\n",
    "dimension_type = 'discard'\n",
    "\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "    \n",
    "for dim_label, dim_feats in dimensions.items():\n",
    "    print(f'Start training with {dim_label} dimension...')\n",
    "\n",
    "    # if dim == 'Pairs':\n",
    "    #     continue\n",
    "\n",
    "    features = []\n",
    "    if dimension_type == 'keep':\n",
    "        features = dim_feats\n",
    "    else:\n",
    "        for lab, dim in dimensions.items():\n",
    "            if lab != dim_label:\n",
    "                features += dim\n",
    "\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    brier_scores = []\n",
    "    feature_importances = []\n",
    "    corr_features = []\n",
    "    redundant_features = []\n",
    "\n",
    "    for fold in range(0, 10):\n",
    "\n",
    "        # if fold in [3, 4]:\n",
    "        #     continue\n",
    "\n",
    "        clone_clf = XGBClassifier(random_state=42)\n",
    "        \n",
    "        # Split training data into features and dims\n",
    "        X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"))\n",
    "        y_train = X_train['related']\n",
    "\n",
    "        # df_test = pd.concat((df_test, X_train.iloc[:1]))\n",
    "        # if (dimension_type == 'keep' and dim_label == 'Pairs') or (dimension_type == 'discard' and dim_label != 'Pairs'):\n",
    "            # desc_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold)\n",
    "        #     subject_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, \"subject\")\n",
    "        #     add_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'added_lines')\n",
    "        #     del_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'deleted_lines')\n",
    "\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_train, 'commit_message', 'desc')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_train, 'subject', 'subject')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_train, 'added_lines', 'add_lines')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_train, 'deleted_lines', 'del_lines')\n",
    "\n",
    "        corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        features = [c for c in features if c not in corr_features]\n",
    "\n",
    "        X_train = X_train[features]\n",
    "\n",
    "        # X_train = X_train.drop(columns=cols_dropped)\n",
    "\n",
    "        # ros = RandomUnderSampler(random_state=0)\n",
    "        \n",
    "        # Perform under-sampling of the majority class(es)\n",
    "        # X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "        # conduct the correlation analysis\n",
    "        # if fold == 0:\n",
    "        \n",
    "\n",
    "        # # Remove highly correlated features from the training set\n",
    "        # X_train = X_train.drop(columns=corr_features)\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        # if len(X_train.columns) > 1:\n",
    "        #     redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "\n",
    "        # Remove indepandent variables explained by others\n",
    "        # if len(redundant_features) != 0:\n",
    "        #     X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # Instantiate the OverSampler class then fit it on the each fold training dataset\n",
    "        # features = X_train.columns.tolist()\n",
    "        # print(f'len(X_train) {len(X_train)}')\n",
    "\n",
    "        # Columns to exclude in the test set\n",
    "        # cols_exluded = corr_features + redundant_features \n",
    "\n",
    "        X_test = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"))\n",
    "        # X_test_pairs = X_test[['Source', 'Target', 'related']]\n",
    "        y_test = X_test['related']\n",
    "\n",
    "        # if (dimension_type == 'keep' and dim_label == 'Pairs') or (dimension_type == 'discard' and dim_label != 'Pairs'):\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'commit_message', 'desc')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_test, 'subject', 'subject')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_test, 'added_lines', 'add_lines')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_test, 'deleted_lines', 'del_lines')\n",
    "        \n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "\n",
    "        # Train the Random Forest Classifier on the training fold set \n",
    "        clone_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_probs = clone_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "        # Set custom threshold\n",
    "        threshold = 0.75\n",
    "        y_pred = [1 if p >= threshold else 0 for p in y_probs]\n",
    "\n",
    "        # y_pred_prob = clone_clf.predict_proba(X_test)[:, 1]\n",
    "        # X_test_pairs['pred'] = y_pred_prob\n",
    "        # compute_top_k_prec_recal(X_test_pairs, dim, fold+1)\n",
    "\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        brier_scores.append(brier_score_loss(y_test, y_pred))\n",
    "\n",
    "        print(f\"{dim_label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}, Brier: {brier_scores[-1]}\")\n",
    "\n",
    "    # feature_importances /= (fold+1)\n",
    "    prec_avg = np.average(precision_scores)\n",
    "    recall_avg = np.average(recall_scores)\n",
    "    auc_avg = np.average(auc_scores)\n",
    "    brier_avg = np.average(brier_scores)\n",
    "\n",
    "    print(f\"{dim_label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}, Brier: {brier_avg}\")\n",
    "\n",
    "    dimension_results[dim_label] += [{\n",
    "        'Dimension': dim_label,\n",
    "        'Precision': prec_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'AUC': auc_avg,\n",
    "        'Brier': brier_avg\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_imp = pd.DataFrame([item[0] for item in list(dimension_results.values())])\n",
    "dim_imp.to_csv(osp.join('.', 'Results', 'Feature_importance', f'second_model_{dimension_type}_dim_new.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = pd.read_csv(osp.join('.', 'Results', 'Impact', f'third_model_feat_impact.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr = \"last_mth_mod_uniq_proj_nbr_target\"\n",
    "# test = df_feat_impact#.loc[(df_feat_impact['fold']!=0)&(df_feat_impact[attr].duplicated()==False), [attr, \"fold\", \"impact\"]].sort_values(\"impact\")\n",
    "# test = test[test['impact'].notnull()==True].iloc[:-1, -1]\n",
    "# test = f\" & {round(test.min(), 2)} & {round(test.median(), 2)} & {round(test.max(), 2)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
